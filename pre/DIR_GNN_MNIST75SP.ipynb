{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFJ9Zle-N1B2",
        "outputId": "96a75efa-f424-4ebf-eb7b-de53250fbb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k70Vxlv9lMRZ",
        "outputId": "7e0d6b62-1bf0-4344-d9ce-b4af5a4a2d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dir-gnn'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 138 (delta 59), reused 88 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (138/138), 6.26 MiB | 17.41 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Wuyxin/dir-gnn.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dir-gnn\n",
        "%mkdir data\n",
        "%cd data\n",
        "%mkdir MNISTSP\n",
        "%cd MNISTSP\n",
        "%mkdir raw\n",
        "%cd raw\n",
        "%cp /content/drive/MyDrive/CS249/mnist_75sp_color_noise.pt .\n",
        "%cp /content/drive/MyDrive/CS249/mnist_75sp_test.pkl .\n",
        "%cp /content/drive/MyDrive/CS249/mnist_75sp_train.pkl .\n",
        "%cd ../../..\n",
        "#!pip install ml-collections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_oOYBvHK0VM",
        "outputId": "47f69765-41f2-44de-f72c-e9f11ca74412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dir-gnn\n",
            "/content/dir-gnn/data\n",
            "/content/dir-gnn/data/MNISTSP\n",
            "/content/dir-gnn/data/MNISTSP/raw\n",
            "/content/dir-gnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torch_sparse\n",
        "!pip install torch_scatter\n",
        "!pip install ogb\n",
        "!pip install texttable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss7NND46T-8B",
        "outputId": "5c9267be-9d1a-447d-9fc5-04be663ffb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 92 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 337 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 348 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 358 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 368 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 378 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 389 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 399 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 407 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=625a9bd120e43ef626dacebf2a2543389b417197c868b9a87f68b9e3cc89ef67\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n",
            "Collecting torch_sparse\n",
            "  Downloading torch_sparse-0.6.13.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch_sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl size=1654973 sha256=9bbbb5f139a7a834ea090f9afef6c299871042469b4c016b5b319a7fe3f38b18\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/01/be/6b2966e0ff20bb023ae35e5d17903e6e5b4df46dd5892f6be6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Collecting torch_scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=3870734 sha256=a2703a63b8004410a50b559b8c425a01c131e43974d9a7e8f374b3192409adc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.11.0+cu113)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=e79eb10e70d540130cc2d0c55711bfadd67ea74d3e0c9667912fceed0c5b6b03\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m train.mnistsp_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lz_d4wzSzLB",
        "outputId": "32f18ac1-1f2e-40c3-d987-8e816b5ef641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing...\n",
            "Done!\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "2022-05-08 21:53:47,236 - /content/dir-gnn/utils/helper.py[line:49] - INFO: +------------+-------+\n",
            "| Parameter  | Value |\n",
            "+------------+-------+\n",
            "| cuda       | 0     |\n",
            "+------------+-------+\n",
            "| datadir    | data/ |\n",
            "+------------+-------+\n",
            "| epoch      | 400   |\n",
            "+------------+-------+\n",
            "| reg        | 1     |\n",
            "+------------+-------+\n",
            "| seed       | [1]   |\n",
            "+------------+-------+\n",
            "| channels   | 32    |\n",
            "+------------+-------+\n",
            "| commit     |       |\n",
            "+------------+-------+\n",
            "| pretrain   | 20    |\n",
            "+------------+-------+\n",
            "| alpha      | 0.000 |\n",
            "+------------+-------+\n",
            "| r          | 0.800 |\n",
            "+------------+-------+\n",
            "| batch_size | 32    |\n",
            "+------------+-------+\n",
            "| net_lr     | 0.001 |\n",
            "+------------+-------+\n",
            "2022-05-08 21:54:59,395 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  0/400]  all_loss:2.406=[XE:2.406  IL:0.000000]  Train_ACC:0.097 Test_ACC[0.101  0.106]  Val_ACC:0.099  \n",
            "2022-05-08 21:55:59,404 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  1/400]  all_loss:2.344=[XE:2.344  IL:0.000000]  Train_ACC:0.105 Test_ACC[0.107  0.100]  Val_ACC:0.106  \n",
            "2022-05-08 21:57:00,069 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  2/400]  all_loss:2.310=[XE:2.310  IL:0.000001]  Train_ACC:0.108 Test_ACC[0.108  0.107]  Val_ACC:0.105  \n",
            "2022-05-08 21:58:00,476 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  3/400]  all_loss:2.285=[XE:2.285  IL:0.000002]  Train_ACC:0.113 Test_ACC[0.108  0.123]  Val_ACC:0.109  \n",
            "2022-05-08 21:59:00,676 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  4/400]  all_loss:2.266=[XE:2.266  IL:0.000004]  Train_ACC:0.116 Test_ACC[0.113  0.131]  Val_ACC:0.117  \n",
            "2022-05-08 22:00:01,403 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  5/400]  all_loss:2.254=[XE:2.254  IL:0.000008]  Train_ACC:0.130 Test_ACC[0.126  0.136]  Val_ACC:0.134  \n",
            "2022-05-08 22:01:01,779 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  6/400]  all_loss:2.243=[XE:2.243  IL:0.000015]  Train_ACC:0.147 Test_ACC[0.144  0.150]  Val_ACC:0.149  \n",
            "2022-05-08 22:02:02,741 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  7/400]  all_loss:2.234=[XE:2.234  IL:0.000026]  Train_ACC:0.171 Test_ACC[0.163  0.163]  Val_ACC:0.170  \n",
            "2022-05-08 22:03:03,229 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  8/400]  all_loss:2.224=[XE:2.224  IL:0.000040]  Train_ACC:0.196 Test_ACC[0.180  0.169]  Val_ACC:0.190  \n",
            "2022-05-08 22:04:03,408 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [  9/400]  all_loss:2.215=[XE:2.215  IL:0.000062]  Train_ACC:0.215 Test_ACC[0.190  0.173]  Val_ACC:0.212  \n",
            "2022-05-08 22:05:03,891 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 10/400]  all_loss:2.206=[XE:2.206  IL:0.000092]  Train_ACC:0.230 Test_ACC[0.202  0.171]  Val_ACC:0.226  \n",
            "2022-05-08 22:06:03,702 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 11/400]  all_loss:2.196=[XE:2.196  IL:0.000138]  Train_ACC:0.239 Test_ACC[0.210  0.166]  Val_ACC:0.234  \n",
            "2022-05-08 22:07:02,059 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 12/400]  all_loss:2.186=[XE:2.186  IL:0.000196]  Train_ACC:0.259 Test_ACC[0.218  0.158]  Val_ACC:0.255  \n",
            "2022-05-08 22:07:59,930 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 13/400]  all_loss:2.175=[XE:2.174  IL:0.000270]  Train_ACC:0.263 Test_ACC[0.219  0.153]  Val_ACC:0.262  \n",
            "2022-05-08 22:08:59,985 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 14/400]  all_loss:2.164=[XE:2.164  IL:0.000383]  Train_ACC:0.270 Test_ACC[0.221  0.153]  Val_ACC:0.267  \n",
            "2022-05-08 22:10:00,802 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 15/400]  all_loss:2.154=[XE:2.153  IL:0.000526]  Train_ACC:0.280 Test_ACC[0.225  0.156]  Val_ACC:0.268  \n",
            "2022-05-08 22:11:01,156 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 16/400]  all_loss:2.141=[XE:2.141  IL:0.000746]  Train_ACC:0.291 Test_ACC[0.228  0.152]  Val_ACC:0.285  \n",
            "2022-05-08 22:12:01,936 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 17/400]  all_loss:2.131=[XE:2.130  IL:0.001000]  Train_ACC:0.295 Test_ACC[0.228  0.154]  Val_ACC:0.285  \n",
            "2022-05-08 22:13:02,427 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 18/400]  all_loss:2.119=[XE:2.117  IL:0.001330]  Train_ACC:0.287 Test_ACC[0.228  0.147]  Val_ACC:0.280  \n",
            "2022-05-08 22:14:02,922 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 19/400]  all_loss:2.108=[XE:2.106  IL:0.001716]  Train_ACC:0.283 Test_ACC[0.225  0.147]  Val_ACC:0.270  \n",
            "2022-05-08 22:15:03,260 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 20/400]  all_loss:2.095=[XE:2.093  IL:0.002212]  Train_ACC:0.278 Test_ACC[0.222  0.142]  Val_ACC:0.266  \n",
            "2022-05-08 22:16:03,340 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 21/400]  all_loss:2.085=[XE:2.082  IL:0.002743]  Train_ACC:0.278 Test_ACC[0.222  0.141]  Val_ACC:0.268  \n",
            "2022-05-08 22:17:03,323 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 22/400]  all_loss:2.073=[XE:2.069  IL:0.003437]  Train_ACC:0.281 Test_ACC[0.227  0.139]  Val_ACC:0.275  \n",
            "2022-05-08 22:18:03,467 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 23/400]  all_loss:2.063=[XE:2.059  IL:0.004176]  Train_ACC:0.290 Test_ACC[0.232  0.137]  Val_ACC:0.289  \n",
            "2022-05-08 22:19:03,478 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 24/400]  all_loss:2.052=[XE:2.047  IL:0.004930]  Train_ACC:0.301 Test_ACC[0.233  0.136]  Val_ACC:0.298  \n",
            "2022-05-08 22:20:03,557 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 25/400]  all_loss:2.042=[XE:2.036  IL:0.005891]  Train_ACC:0.302 Test_ACC[0.232  0.134]  Val_ACC:0.297  \n",
            "2022-05-08 22:21:03,527 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 26/400]  all_loss:2.030=[XE:2.023  IL:0.006938]  Train_ACC:0.301 Test_ACC[0.231  0.131]  Val_ACC:0.294  \n",
            "2022-05-08 22:22:03,399 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 27/400]  all_loss:2.020=[XE:2.012  IL:0.008117]  Train_ACC:0.304 Test_ACC[0.227  0.133]  Val_ACC:0.295  \n",
            "2022-05-08 22:23:03,170 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 28/400]  all_loss:2.011=[XE:2.002  IL:0.009170]  Train_ACC:0.313 Test_ACC[0.235  0.129]  Val_ACC:0.311  \n",
            "2022-05-08 22:24:02,728 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 29/400]  all_loss:2.000=[XE:1.989  IL:0.010931]  Train_ACC:0.328 Test_ACC[0.243  0.132]  Val_ACC:0.327  \n",
            "2022-05-08 22:25:02,579 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 30/400]  all_loss:1.990=[XE:1.977  IL:0.012267]  Train_ACC:0.332 Test_ACC[0.243  0.141]  Val_ACC:0.332  \n",
            "2022-05-08 22:26:02,156 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 31/400]  all_loss:1.979=[XE:1.964  IL:0.014210]  Train_ACC:0.337 Test_ACC[0.244  0.142]  Val_ACC:0.336  \n",
            "2022-05-08 22:27:01,625 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 32/400]  all_loss:1.967=[XE:1.951  IL:0.015725]  Train_ACC:0.339 Test_ACC[0.243  0.146]  Val_ACC:0.340  \n",
            "2022-05-08 22:28:01,744 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 33/400]  all_loss:1.956=[XE:1.939  IL:0.017426]  Train_ACC:0.347 Test_ACC[0.247  0.147]  Val_ACC:0.350  \n",
            "2022-05-08 22:29:01,715 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 34/400]  all_loss:1.946=[XE:1.926  IL:0.019393]  Train_ACC:0.336 Test_ACC[0.240  0.160]  Val_ACC:0.340  \n",
            "2022-05-08 22:30:01,969 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 35/400]  all_loss:1.933=[XE:1.912  IL:0.021369]  Train_ACC:0.347 Test_ACC[0.245  0.157]  Val_ACC:0.352  \n",
            "2022-05-08 22:31:01,734 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 36/400]  all_loss:1.921=[XE:1.898  IL:0.023450]  Train_ACC:0.353 Test_ACC[0.243  0.160]  Val_ACC:0.353  \n",
            "2022-05-08 22:32:01,656 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 37/400]  all_loss:1.912=[XE:1.886  IL:0.025682]  Train_ACC:0.357 Test_ACC[0.244  0.169]  Val_ACC:0.360  \n",
            "2022-05-08 22:33:02,005 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 38/400]  all_loss:1.898=[XE:1.870  IL:0.027250]  Train_ACC:0.367 Test_ACC[0.246  0.167]  Val_ACC:0.370  \n",
            "2022-05-08 22:34:01,930 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 39/400]  all_loss:1.887=[XE:1.856  IL:0.030499]  Train_ACC:0.374 Test_ACC[0.243  0.171]  Val_ACC:0.373  \n",
            "2022-05-08 22:35:00,133 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 40/400]  all_loss:1.873=[XE:1.841  IL:0.031639]  Train_ACC:0.386 Test_ACC[0.243  0.168]  Val_ACC:0.389  \n",
            "2022-05-08 22:35:57,879 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 41/400]  all_loss:1.862=[XE:1.828  IL:0.033645]  Train_ACC:0.383 Test_ACC[0.245  0.171]  Val_ACC:0.387  \n",
            "2022-05-08 22:36:55,695 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 42/400]  all_loss:1.846=[XE:1.811  IL:0.035123]  Train_ACC:0.398 Test_ACC[0.250  0.170]  Val_ACC:0.402  \n",
            "2022-05-08 22:37:53,571 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 43/400]  all_loss:1.834=[XE:1.796  IL:0.037164]  Train_ACC:0.391 Test_ACC[0.243  0.171]  Val_ACC:0.385  \n",
            "2022-05-08 22:38:50,852 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 44/400]  all_loss:1.820=[XE:1.782  IL:0.038476]  Train_ACC:0.406 Test_ACC[0.245  0.171]  Val_ACC:0.406  \n",
            "2022-05-08 22:39:48,182 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 45/400]  all_loss:1.805=[XE:1.764  IL:0.041026]  Train_ACC:0.370 Test_ACC[0.248  0.168]  Val_ACC:0.370  \n",
            "2022-05-08 22:40:45,782 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 46/400]  all_loss:1.792=[XE:1.748  IL:0.044668]  Train_ACC:0.381 Test_ACC[0.228  0.176]  Val_ACC:0.378  \n",
            "2022-05-08 22:41:43,056 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 47/400]  all_loss:1.777=[XE:1.730  IL:0.046764]  Train_ACC:0.434 Test_ACC[0.246  0.167]  Val_ACC:0.433  \n",
            "2022-05-08 22:42:40,634 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 48/400]  all_loss:1.765=[XE:1.712  IL:0.052779]  Train_ACC:0.425 Test_ACC[0.249  0.169]  Val_ACC:0.428  \n",
            "2022-05-08 22:43:38,057 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 49/400]  all_loss:1.748=[XE:1.694  IL:0.053942]  Train_ACC:0.423 Test_ACC[0.230  0.171]  Val_ACC:0.426  \n",
            "2022-05-08 22:44:35,452 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 50/400]  all_loss:1.735=[XE:1.679  IL:0.056243]  Train_ACC:0.372 Test_ACC[0.242  0.165]  Val_ACC:0.367  \n",
            "2022-05-08 22:45:33,221 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 51/400]  all_loss:1.726=[XE:1.663  IL:0.062789]  Train_ACC:0.444 Test_ACC[0.223  0.170]  Val_ACC:0.436  \n",
            "2022-05-08 22:46:30,697 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 52/400]  all_loss:1.708=[XE:1.639  IL:0.069725]  Train_ACC:0.467 Test_ACC[0.236  0.163]  Val_ACC:0.465  \n",
            "2022-05-08 22:47:28,682 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 53/400]  all_loss:1.687=[XE:1.622  IL:0.065392]  Train_ACC:0.415 Test_ACC[0.247  0.162]  Val_ACC:0.414  \n",
            "2022-05-08 22:48:26,152 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 54/400]  all_loss:1.679=[XE:1.606  IL:0.073312]  Train_ACC:0.452 Test_ACC[0.214  0.162]  Val_ACC:0.446  \n",
            "2022-05-08 22:49:23,608 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 55/400]  all_loss:1.664=[XE:1.586  IL:0.078336]  Train_ACC:0.462 Test_ACC[0.230  0.159]  Val_ACC:0.457  \n",
            "2022-05-08 22:50:21,604 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 56/400]  all_loss:1.646=[XE:1.565  IL:0.080350]  Train_ACC:0.445 Test_ACC[0.246  0.153]  Val_ACC:0.444  \n",
            "2022-05-08 22:51:19,160 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 57/400]  all_loss:1.635=[XE:1.560  IL:0.074940]  Train_ACC:0.472 Test_ACC[0.216  0.156]  Val_ACC:0.465  \n",
            "2022-05-08 22:52:16,626 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 58/400]  all_loss:1.618=[XE:1.531  IL:0.086708]  Train_ACC:0.488 Test_ACC[0.228  0.155]  Val_ACC:0.484  \n",
            "2022-05-08 22:53:14,435 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 59/400]  all_loss:1.611=[XE:1.514  IL:0.097327]  Train_ACC:0.482 Test_ACC[0.241  0.143]  Val_ACC:0.484  \n",
            "2022-05-08 22:54:11,833 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 60/400]  all_loss:1.593=[XE:1.503  IL:0.090798]  Train_ACC:0.519 Test_ACC[0.218  0.146]  Val_ACC:0.514  \n",
            "2022-05-08 22:55:09,803 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 61/400]  all_loss:1.581=[XE:1.481  IL:0.099916]  Train_ACC:0.484 Test_ACC[0.222  0.144]  Val_ACC:0.474  \n",
            "2022-05-08 22:56:07,311 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 62/400]  all_loss:1.574=[XE:1.465  IL:0.108989]  Train_ACC:0.495 Test_ACC[0.235  0.134]  Val_ACC:0.500  \n",
            "2022-05-08 22:57:05,122 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 63/400]  all_loss:1.555=[XE:1.453  IL:0.102109]  Train_ACC:0.518 Test_ACC[0.216  0.134]  Val_ACC:0.512  \n",
            "2022-05-08 22:58:03,117 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 64/400]  all_loss:1.549=[XE:1.430  IL:0.118647]  Train_ACC:0.529 Test_ACC[0.230  0.135]  Val_ACC:0.526  \n",
            "2022-05-08 22:59:00,836 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 65/400]  all_loss:1.531=[XE:1.412  IL:0.119406]  Train_ACC:0.492 Test_ACC[0.235  0.133]  Val_ACC:0.485  \n",
            "2022-05-08 22:59:58,502 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 66/400]  all_loss:1.523=[XE:1.410  IL:0.113161]  Train_ACC:0.535 Test_ACC[0.212  0.129]  Val_ACC:0.532  \n",
            "2022-05-08 23:00:56,559 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 67/400]  all_loss:1.510=[XE:1.376  IL:0.134063]  Train_ACC:0.540 Test_ACC[0.224  0.127]  Val_ACC:0.540  \n",
            "2022-05-08 23:01:53,945 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 68/400]  all_loss:1.499=[XE:1.363  IL:0.135443]  Train_ACC:0.528 Test_ACC[0.226  0.131]  Val_ACC:0.519  \n",
            "2022-05-08 23:02:51,769 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 69/400]  all_loss:1.486=[XE:1.357  IL:0.128175]  Train_ACC:0.545 Test_ACC[0.220  0.133]  Val_ACC:0.542  \n",
            "2022-05-08 23:03:49,469 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 70/400]  all_loss:1.478=[XE:1.332  IL:0.145692]  Train_ACC:0.502 Test_ACC[0.234  0.119]  Val_ACC:0.496  \n",
            "2022-05-08 23:04:46,889 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 71/400]  all_loss:1.475=[XE:1.333  IL:0.141535]  Train_ACC:0.537 Test_ACC[0.209  0.131]  Val_ACC:0.535  \n",
            "2022-05-08 23:05:44,709 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 72/400]  all_loss:1.467=[XE:1.305  IL:0.161741]  Train_ACC:0.527 Test_ACC[0.232  0.119]  Val_ACC:0.523  \n",
            "2022-05-08 23:06:42,180 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 73/400]  all_loss:1.453=[XE:1.295  IL:0.158420]  Train_ACC:0.562 Test_ACC[0.229  0.123]  Val_ACC:0.559  \n",
            "2022-05-08 23:07:39,893 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 74/400]  all_loss:1.441=[XE:1.286  IL:0.154951]  Train_ACC:0.583 Test_ACC[0.215  0.125]  Val_ACC:0.575  \n",
            "2022-05-08 23:08:37,614 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 75/400]  all_loss:1.433=[XE:1.266  IL:0.167567]  Train_ACC:0.546 Test_ACC[0.227  0.115]  Val_ACC:0.544  \n",
            "2022-05-08 23:09:35,127 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 76/400]  all_loss:1.426=[XE:1.263  IL:0.163385]  Train_ACC:0.543 Test_ACC[0.218  0.127]  Val_ACC:0.533  \n",
            "2022-05-08 23:10:33,038 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 77/400]  all_loss:1.420=[XE:1.243  IL:0.177071]  Train_ACC:0.604 Test_ACC[0.229  0.122]  Val_ACC:0.595  \n",
            "2022-05-08 23:11:30,542 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 78/400]  all_loss:1.405=[XE:1.229  IL:0.176107]  Train_ACC:0.575 Test_ACC[0.218  0.120]  Val_ACC:0.566  \n",
            "2022-05-08 23:12:28,278 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 79/400]  all_loss:1.405=[XE:1.230  IL:0.174522]  Train_ACC:0.549 Test_ACC[0.217  0.122]  Val_ACC:0.539  \n",
            "2022-05-08 23:13:25,512 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 80/400]  all_loss:1.409=[XE:1.209  IL:0.200517]  Train_ACC:0.529 Test_ACC[0.224  0.118]  Val_ACC:0.523  \n",
            "2022-05-08 23:14:23,046 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 81/400]  all_loss:1.405=[XE:1.208  IL:0.197040]  Train_ACC:0.584 Test_ACC[0.205  0.125]  Val_ACC:0.583  \n",
            "2022-05-08 23:15:20,651 - /content/dir-gnn/train/mnistsp_dir.py[line:231] - INFO: Epoch [ 82/400]  all_loss:1.408=[XE:1.188  IL:0.220387]  Train_ACC:0.521 Test_ACC[0.220  0.120]  Val_ACC:0.513  \n",
            "2022-05-08 23:15:20,651 - /content/dir-gnn/train/mnistsp_dir.py[line:241] - INFO: Early Stopping\n",
            "2022-05-08 23:15:20,658 - /content/dir-gnn/train/mnistsp_dir.py[line:251] - INFO: ====================================================================================================\n",
            "2022-05-08 23:15:20,659 - /content/dir-gnn/train/mnistsp_dir.py[line:257] - INFO: Causal ACC:0.2202-+-nan  Conf ACC:0.1196-+-nan  Train ACC:0.5210-+-nan  Val ACC:0.5128-+-nan  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DIR-GNN-MNIST75SP",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
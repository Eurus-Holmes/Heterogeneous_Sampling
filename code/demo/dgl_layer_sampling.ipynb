{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dgl_layer_sampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEwc3fs0ntZT",
        "outputId": "5bec274f-e7ec-40fd-ec4d-e89b4e764d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Requirement already satisfied: dgl-cu101 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: dglgo in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (4.64.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (0.4.1)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (1.9.1)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.7/dist-packages (from dglgo) (0.17.21)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (1.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from dglgo) (6.0)\n",
            "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.7/dist-packages (from dglgo) (5.10.1)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (1.3.1)\n",
            "Requirement already satisfied: pycodestyle>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from autopep8>=1.6.0->dglgo) (2.8.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from autopep8>=1.6.0->dglgo) (0.10.2)\n",
            "Requirement already satisfied: sphinx>=3.0 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (4.5.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.9.0->dglgo) (4.2.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.6.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.10.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (4.11.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (21.3)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.3.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: docutils<0.18,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.17.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2022.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.8.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.0->dglgo) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl-cu101 dglgo -f https://data.dgl.ai/wheels/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dmlc/dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9sNT9HEqZIW",
        "outputId": "97dfe2e1-d7ab-4466-c7dc-b923fdbb85fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dgl'...\n",
            "remote: Enumerating objects: 30605, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 30605 (delta 3), reused 2 (delta 2), pack-reused 30599\u001b[K\n",
            "Receiving objects: 100% (30605/30605), 17.62 MiB | 28.19 MiB/s, done.\n",
            "Resolving deltas: 100% (19719/19719), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dgl/examples/pytorch/rgcn-hetero/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe8Tb8LdqecL",
        "outputId": "4855729c-2859-4fd2-ecb2-2f4915d9147a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dgl/examples/pytorch/rgcn-hetero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests torch rdflib pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcywh0ouqwNt",
        "outputId": "ff906294-a3ce-4610-864e-6f355c4b776c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib) (4.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib) (3.0.9)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 764 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib) (3.8.0)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d aifb --testing --gpu 0 --fanout=8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-3jlNnlq1xb",
        "outputId": "6c2b1add-2e3b-4417-84aa-8fe4a26768d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='aifb', dropout=0, fanout=8, gpu=0, l2norm=0, lr=0.01, model_path=None, n_bases=-1, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.2100 | Train Loss: 1.4318 | Time: 0.2077\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.5000 | Train Loss: 1.3439 | Time: 0.2037\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.7214 | Valid loss: 1.1116 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.7400 | Train Loss: 1.1083 | Time: 0.2020\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.7000 | Train Loss: 1.0137 | Time: 0.2031\n",
            "Epoch 00001 | Valid Acc: 0.7714 | Valid loss: 0.8641 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.7800 | Train Loss: 0.8869 | Time: 0.2087\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.8500 | Train Loss: 0.7224 | Time: 0.2100\n",
            "Epoch 00002 | Valid Acc: 0.8571 | Valid loss: 0.6766 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.8400 | Train Loss: 0.6822 | Time: 0.2094\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.8500 | Train Loss: 0.5537 | Time: 0.2058\n",
            "Epoch 00003 | Valid Acc: 0.8857 | Valid loss: 0.5054 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.9100 | Train Loss: 0.4765 | Time: 0.2057\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.8750 | Train Loss: 0.5119 | Time: 0.2057\n",
            "Epoch 00004 | Valid Acc: 0.9286 | Valid loss: 0.3788 | Time: 0.5059\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.9300 | Train Loss: 0.3817 | Time: 0.2060\n",
            "Epoch 00005 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.3406 | Time: 0.2058\n",
            "Epoch 00005 | Valid Acc: 0.9357 | Valid loss: 0.2882 | Time: 0.5058\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9300 | Train Loss: 0.3187 | Time: 0.2107\n",
            "Epoch 00006 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1798 | Time: 0.2235\n",
            "Epoch 00006 | Valid Acc: 0.9500 | Valid loss: 0.2239 | Time: 0.5147\n",
            "Epoch 00007 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.2317 | Time: 0.2131\n",
            "Epoch 00007 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1913 | Time: 0.2092\n",
            "Epoch 00007 | Valid Acc: 0.9500 | Valid loss: 0.1814 | Time: 0.5234\n",
            "Epoch 00008 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.2059 | Time: 0.2025\n",
            "Epoch 00008 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.1179 | Time: 0.2056\n",
            "Epoch 00008 | Valid Acc: 0.9500 | Valid loss: 0.1601 | Time: 0.5189\n",
            "Epoch 00009 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1720 | Time: 0.2030\n",
            "Epoch 00009 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.1045 | Time: 0.2066\n",
            "Epoch 00009 | Valid Acc: 0.9571 | Valid loss: 0.1323 | Time: 0.5170\n",
            "Epoch 00010 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.1228 | Time: 0.2058\n",
            "Epoch 00010 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.1351 | Time: 0.2099\n",
            "Epoch 00010 | Valid Acc: 0.9714 | Valid loss: 0.1139 | Time: 0.5199\n",
            "Epoch 00011 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0917 | Time: 0.2096\n",
            "Epoch 00011 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1622 | Time: 0.2046\n",
            "Epoch 00011 | Valid Acc: 0.9714 | Valid loss: 0.0976 | Time: 0.5185\n",
            "Epoch 00012 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.1077 | Time: 0.2025\n",
            "Epoch 00012 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0781 | Time: 0.2063\n",
            "Epoch 00012 | Valid Acc: 0.9714 | Valid loss: 0.0872 | Time: 0.5166\n",
            "Epoch 00013 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0894 | Time: 0.2061\n",
            "Epoch 00013 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0789 | Time: 0.2078\n",
            "Epoch 00013 | Valid Acc: 0.9714 | Valid loss: 0.0779 | Time: 0.5158\n",
            "Epoch 00014 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0734 | Time: 0.2196\n",
            "Epoch 00014 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0803 | Time: 0.2072\n",
            "Epoch 00014 | Valid Acc: 0.9786 | Valid loss: 0.0674 | Time: 0.5162\n",
            "Epoch 00015 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0831 | Time: 0.2106\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0292 | Time: 0.2322\n",
            "Epoch 00015 | Valid Acc: 0.9857 | Valid loss: 0.0591 | Time: 0.5179\n",
            "Epoch 00016 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0559 | Time: 0.2073\n",
            "Epoch 00016 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0668 | Time: 0.2071\n",
            "Epoch 00016 | Valid Acc: 0.9857 | Valid loss: 0.0526 | Time: 0.5174\n",
            "Epoch 00017 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0350 | Time: 0.2062\n",
            "Epoch 00017 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0882 | Time: 0.2027\n",
            "Epoch 00017 | Valid Acc: 0.9857 | Valid loss: 0.0459 | Time: 0.5163\n",
            "Epoch 00018 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0410 | Time: 0.2361\n",
            "Epoch 00018 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0533 | Time: 0.2040\n",
            "Epoch 00018 | Valid Acc: 0.9857 | Valid loss: 0.0388 | Time: 0.5173\n",
            "Epoch 00019 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0386 | Time: 0.2065\n",
            "Epoch 00019 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0402 | Time: 0.2053\n",
            "Epoch 00019 | Valid Acc: 0.9857 | Valid loss: 0.0345 | Time: 0.5166\n",
            "\n",
            "100% 73/73 [00:08<00:00,  8.64it/s]\n",
            "100% 73/73 [00:08<00:00,  8.12it/s]\n",
            "Test Acc: 0.9444\n",
            "\n",
            "Total time: : 8.3448s | Batch time: : 0.2086s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d mutag --l2norm 5e-4 --testing --gpu 0 --fanout=8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rma2GPo2uhFU",
        "outputId": "0f57e94a-ba79-4b01-ec5a-0bd420dc0bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='mutag', dropout=0, fanout=8, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=-1, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.5300 | Train Loss: 0.6918 | Time: 0.1238\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.5700 | Train Loss: 0.6877 | Time: 0.1280\n",
            "Epoch 00000 | Batch 002 | Train Acc: 0.6111 | Train Loss: 0.6688 | Time: 0.1216\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.6103 | Valid loss: 0.6187 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.6300 | Train Loss: 0.6003 | Time: 0.1215\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.6100 | Train Loss: 0.6006 | Time: 0.1157\n",
            "Epoch 00001 | Batch 002 | Train Acc: 0.5833 | Train Loss: 0.5879 | Time: 0.1129\n",
            "Epoch 00001 | Valid Acc: 0.6397 | Valid loss: 0.5172 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.6500 | Train Loss: 0.5084 | Time: 0.1113\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.7800 | Train Loss: 0.4807 | Time: 0.1113\n",
            "Epoch 00002 | Batch 002 | Train Acc: 0.8611 | Train Loss: 0.4678 | Time: 0.1120\n",
            "Epoch 00002 | Valid Acc: 0.9412 | Valid loss: 0.3919 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.3896 | Time: 0.1138\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.9300 | Train Loss: 0.3481 | Time: 0.1123\n",
            "Epoch 00003 | Batch 002 | Train Acc: 0.9444 | Train Loss: 0.3388 | Time: 0.1116\n",
            "Epoch 00003 | Valid Acc: 0.9485 | Valid loss: 0.2741 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.2869 | Time: 0.1121\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.9700 | Train Loss: 0.2373 | Time: 0.1103\n",
            "Epoch 00004 | Batch 002 | Train Acc: 0.9861 | Train Loss: 0.1951 | Time: 0.1102\n",
            "Epoch 00004 | Valid Acc: 1.0000 | Valid loss: 0.1720 | Time: 0.4158\n",
            "Epoch 00005 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.1770 | Time: 0.1126\n",
            "Epoch 00005 | Batch 001 | Train Acc: 0.9900 | Train Loss: 0.1483 | Time: 0.1117\n",
            "Epoch 00005 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.1326 | Time: 0.1128\n",
            "Epoch 00005 | Valid Acc: 1.0000 | Valid loss: 0.0992 | Time: 0.4172\n",
            "Epoch 00006 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0952 | Time: 0.1091\n",
            "Epoch 00006 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0750 | Time: 0.1150\n",
            "Epoch 00006 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0908 | Time: 0.1128\n",
            "Epoch 00006 | Valid Acc: 1.0000 | Valid loss: 0.0650 | Time: 0.4172\n",
            "Epoch 00007 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0850 | Time: 0.1111\n",
            "Epoch 00007 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0489 | Time: 0.1136\n",
            "Epoch 00007 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0412 | Time: 0.1458\n",
            "Epoch 00007 | Valid Acc: 1.0000 | Valid loss: 0.0339 | Time: 0.4252\n",
            "Epoch 00008 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0350 | Time: 0.1120\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0307 | Time: 0.1139\n",
            "Epoch 00008 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0235 | Time: 0.1133\n",
            "Epoch 00008 | Valid Acc: 1.0000 | Valid loss: 0.0248 | Time: 0.4250\n",
            "Epoch 00009 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0271 | Time: 0.1115\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0510 | Time: 0.1151\n",
            "Epoch 00009 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0372 | Time: 0.1115\n",
            "Epoch 00009 | Valid Acc: 1.0000 | Valid loss: 0.0155 | Time: 0.4234\n",
            "Epoch 00010 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0149 | Time: 0.1174\n",
            "Epoch 00010 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0132 | Time: 0.1115\n",
            "Epoch 00010 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0110 | Time: 0.1150\n",
            "Epoch 00010 | Valid Acc: 1.0000 | Valid loss: 0.0125 | Time: 0.4240\n",
            "Epoch 00011 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0124 | Time: 0.1126\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0121 | Time: 0.1133\n",
            "Epoch 00011 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0146 | Time: 0.1114\n",
            "Epoch 00011 | Valid Acc: 1.0000 | Valid loss: 0.0135 | Time: 0.4232\n",
            "Epoch 00012 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0164 | Time: 0.1092\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0161 | Time: 0.1100\n",
            "Epoch 00012 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0085 | Time: 0.1114\n",
            "Epoch 00012 | Valid Acc: 1.0000 | Valid loss: 0.0100 | Time: 0.4219\n",
            "Epoch 00013 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0067 | Time: 0.1120\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0068 | Time: 0.1106\n",
            "Epoch 00013 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0086 | Time: 0.1106\n",
            "Epoch 00013 | Valid Acc: 1.0000 | Valid loss: 0.0059 | Time: 0.4209\n",
            "Epoch 00014 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0055 | Time: 0.1109\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0067 | Time: 0.1124\n",
            "Epoch 00014 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0056 | Time: 0.1169\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0061 | Time: 0.4208\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0063 | Time: 0.1133\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0048 | Time: 0.1188\n",
            "Epoch 00015 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0066 | Time: 0.1165\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0059 | Time: 0.4218\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0050 | Time: 0.1165\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0065 | Time: 0.1129\n",
            "Epoch 00016 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0052 | Time: 0.1428\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0058 | Time: 0.4247\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0041 | Time: 0.1136\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0044 | Time: 0.1190\n",
            "Epoch 00017 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0034 | Time: 0.1137\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0041 | Time: 0.4250\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0037 | Time: 0.1120\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0039 | Time: 0.1173\n",
            "Epoch 00018 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0040 | Time: 0.1144\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0045 | Time: 0.4252\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0040 | Time: 0.1140\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0052 | Time: 0.1133\n",
            "Epoch 00019 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0043 | Time: 0.1166\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0042 | Time: 0.4252\n",
            "\n",
            "Total time: : 6.8889s | Batch time: : 0.1148s\n",
            "100% 272/272 [00:15<00:00, 17.16it/s]\n",
            "100% 272/272 [00:16<00:00, 16.14it/s]\n",
            "Test Acc: 0.7206\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d bgs --l2norm 5e-4 --n-bases 40 --testing --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfj9x_Z27MPH",
        "outputId": "ac287ced-5d5b-4735-f085-d0a887052965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='bgs', dropout=0, fanout=4, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=40, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.4600 | Train Loss: 1.0240 | Time: 0.2427\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.5882 | Train Loss: 0.6731 | Time: 0.2373\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.6325 | Valid loss: 0.9770 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.6300 | Train Loss: 0.9709 | Time: 0.2404\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.6471 | Train Loss: 1.0073 | Time: 0.2433\n",
            "Epoch 00001 | Valid Acc: 0.6325 | Valid loss: 0.6292 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.6400 | Train Loss: 0.6139 | Time: 0.2430\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.7647 | Train Loss: 0.4762 | Time: 0.2383\n",
            "Epoch 00002 | Valid Acc: 0.8974 | Valid loss: 0.3228 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.9100 | Train Loss: 0.3111 | Time: 0.2457\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.7647 | Train Loss: 0.4239 | Time: 0.2454\n",
            "Epoch 00003 | Valid Acc: 0.8376 | Valid loss: 0.3415 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.8500 | Train Loss: 0.3425 | Time: 0.2422\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.8235 | Train Loss: 0.3624 | Time: 0.2419\n",
            "Epoch 00004 | Valid Acc: 0.8803 | Valid loss: 0.2948 | Time: 0.6842\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.8900 | Train Loss: 0.2703 | Time: 0.2528\n",
            "Epoch 00005 | Batch 001 | Train Acc: 0.7647 | Train Loss: 0.3200 | Time: 0.2481\n",
            "Epoch 00005 | Valid Acc: 0.9487 | Valid loss: 0.1699 | Time: 0.6966\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1828 | Time: 0.2449\n",
            "Epoch 00006 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0709 | Time: 0.2402\n",
            "Epoch 00006 | Valid Acc: 0.9487 | Valid loss: 0.1136 | Time: 0.7042\n",
            "Epoch 00007 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.1052 | Time: 0.2411\n",
            "Epoch 00007 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.1413 | Time: 0.2398\n",
            "Epoch 00007 | Valid Acc: 0.9487 | Valid loss: 0.0926 | Time: 0.6985\n",
            "Epoch 00008 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.0924 | Time: 0.2431\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0797 | Time: 0.2365\n",
            "Epoch 00008 | Valid Acc: 0.9487 | Valid loss: 0.0831 | Time: 0.7015\n",
            "Epoch 00009 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.0964 | Time: 0.2508\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0024 | Time: 0.2440\n",
            "Epoch 00009 | Valid Acc: 0.9487 | Valid loss: 0.0778 | Time: 0.7007\n",
            "Epoch 00010 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.0712 | Time: 0.2392\n",
            "Epoch 00010 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.1099 | Time: 0.2383\n",
            "Epoch 00010 | Valid Acc: 0.9573 | Valid loss: 0.0688 | Time: 0.6973\n",
            "Epoch 00011 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.0764 | Time: 0.2476\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0244 | Time: 0.2364\n",
            "Epoch 00011 | Valid Acc: 0.9829 | Valid loss: 0.0588 | Time: 0.6964\n",
            "Epoch 00012 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0586 | Time: 0.2445\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0561 | Time: 0.2412\n",
            "Epoch 00012 | Valid Acc: 1.0000 | Valid loss: 0.0468 | Time: 0.6954\n",
            "Epoch 00013 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0452 | Time: 0.2431\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0544 | Time: 0.2429\n",
            "Epoch 00013 | Valid Acc: 1.0000 | Valid loss: 0.0389 | Time: 0.6982\n",
            "Epoch 00014 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0388 | Time: 0.2464\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0411 | Time: 0.2373\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0313 | Time: 0.6972\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0276 | Time: 0.2449\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0496 | Time: 0.2363\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0260 | Time: 0.6958\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0183 | Time: 0.2410\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0645 | Time: 0.2433\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0212 | Time: 0.6950\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0208 | Time: 0.2532\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0178 | Time: 0.2399\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0166 | Time: 0.6950\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0188 | Time: 0.2403\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0118 | Time: 0.2966\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0138 | Time: 0.6981\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0156 | Time: 0.2415\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0045 | Time: 0.2378\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0114 | Time: 0.6969\n",
            "\n",
            "Total time: : 9.7527s | Batch time: : 0.2438s\n",
            "100% 949/949 [02:36<00:00,  6.05it/s]\n",
            "100% 949/949 [02:43<00:00,  5.79it/s]\n",
            "Test Acc: 0.8966\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d am --l2norm 5e-4 --n-bases 40 --testing --gpu 0  --fanout=16 --batch-size 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POopSO1F7V_j",
        "outputId": "7b8fecfc-d7b8-42ea-b133-a0aac8b21391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=50, data_cpu=False, dataset='am', dropout=0, fanout=16, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=40, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.1200 | Train Loss: 2.3962 | Time: 0.2382\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.2200 | Train Loss: 2.3297 | Time: 0.2414\n",
            "Epoch 00000 | Batch 002 | Train Acc: 0.4000 | Train Loss: 2.1839 | Time: 0.2384\n",
            "Epoch 00000 | Batch 003 | Train Acc: 0.3400 | Train Loss: 2.0752 | Time: 0.2347\n",
            "Epoch 00000 | Batch 004 | Train Acc: 0.4600 | Train Loss: 1.8620 | Time: 0.2434\n",
            "Epoch 00000 | Batch 005 | Train Acc: 0.4000 | Train Loss: 1.6405 | Time: 0.2354\n",
            "Epoch 00000 | Batch 006 | Train Acc: 0.3000 | Train Loss: 1.8635 | Time: 0.2658\n",
            "Epoch 00000 | Batch 007 | Train Acc: 0.2600 | Train Loss: 2.5773 | Time: 0.2324\n",
            "Epoch 00000 | Batch 008 | Train Acc: 0.3400 | Train Loss: 2.1144 | Time: 0.2336\n",
            "Epoch 00000 | Batch 009 | Train Acc: 0.5000 | Train Loss: 1.8385 | Time: 0.2380\n",
            "Epoch 00000 | Batch 010 | Train Acc: 0.5000 | Train Loss: 1.7109 | Time: 0.2393\n",
            "Epoch 00000 | Batch 011 | Train Acc: 0.5400 | Train Loss: 1.7357 | Time: 0.2358\n",
            "Epoch 00000 | Batch 012 | Train Acc: 0.5800 | Train Loss: 1.2826 | Time: 0.2342\n",
            "Epoch 00000 | Batch 013 | Train Acc: 0.6200 | Train Loss: 1.3643 | Time: 0.2366\n",
            "Epoch 00000 | Batch 014 | Train Acc: 0.7200 | Train Loss: 0.8936 | Time: 0.2346\n",
            "Epoch 00000 | Batch 015 | Train Acc: 0.8400 | Train Loss: 0.8262 | Time: 0.2344\n",
            "Epoch 00000 | Batch 016 | Train Acc: 0.5000 | Train Loss: 2.9552 | Time: 0.2308\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.8379 | Valid loss: 0.7160 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.9200 | Train Loss: 0.5011 | Time: 0.2467\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.8600 | Train Loss: 0.6439 | Time: 0.2400\n",
            "Epoch 00001 | Batch 002 | Train Acc: 0.9000 | Train Loss: 0.6084 | Time: 0.2340\n",
            "Epoch 00001 | Batch 003 | Train Acc: 0.9000 | Train Loss: 0.5676 | Time: 0.2389\n",
            "Epoch 00001 | Batch 004 | Train Acc: 0.8800 | Train Loss: 0.5679 | Time: 0.2504\n",
            "Epoch 00001 | Batch 005 | Train Acc: 0.8400 | Train Loss: 0.5039 | Time: 0.2368\n",
            "Epoch 00001 | Batch 006 | Train Acc: 0.9600 | Train Loss: 0.2863 | Time: 0.2376\n",
            "Epoch 00001 | Batch 007 | Train Acc: 0.9000 | Train Loss: 0.3634 | Time: 0.2417\n",
            "Epoch 00001 | Batch 008 | Train Acc: 0.9000 | Train Loss: 0.4995 | Time: 0.2436\n",
            "Epoch 00001 | Batch 009 | Train Acc: 0.9400 | Train Loss: 0.3353 | Time: 0.2339\n",
            "Epoch 00001 | Batch 010 | Train Acc: 0.9600 | Train Loss: 0.1662 | Time: 0.2402\n",
            "Epoch 00001 | Batch 011 | Train Acc: 0.9400 | Train Loss: 0.1489 | Time: 0.2362\n",
            "Epoch 00001 | Batch 012 | Train Acc: 0.8600 | Train Loss: 0.4595 | Time: 0.2405\n",
            "Epoch 00001 | Batch 013 | Train Acc: 0.8800 | Train Loss: 0.4387 | Time: 0.2395\n",
            "Epoch 00001 | Batch 014 | Train Acc: 0.8800 | Train Loss: 0.6871 | Time: 0.2404\n",
            "Epoch 00001 | Batch 015 | Train Acc: 0.9400 | Train Loss: 0.1666 | Time: 0.2425\n",
            "Epoch 00001 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.2973 | Time: 0.2232\n",
            "Epoch 00001 | Valid Acc: 0.9601 | Valid loss: 0.1282 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1651 | Time: 0.2392\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.9400 | Train Loss: 0.1067 | Time: 0.2394\n",
            "Epoch 00002 | Batch 002 | Train Acc: 0.9400 | Train Loss: 0.1619 | Time: 0.2452\n",
            "Epoch 00002 | Batch 003 | Train Acc: 0.9800 | Train Loss: 0.0895 | Time: 0.2379\n",
            "Epoch 00002 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0303 | Time: 0.2348\n",
            "Epoch 00002 | Batch 005 | Train Acc: 0.9000 | Train Loss: 0.2958 | Time: 0.2435\n",
            "Epoch 00002 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0034 | Time: 0.2405\n",
            "Epoch 00002 | Batch 007 | Train Acc: 0.9400 | Train Loss: 0.1499 | Time: 0.2399\n",
            "Epoch 00002 | Batch 008 | Train Acc: 0.9600 | Train Loss: 0.2778 | Time: 0.2389\n",
            "Epoch 00002 | Batch 009 | Train Acc: 0.9600 | Train Loss: 0.0860 | Time: 0.2408\n",
            "Epoch 00002 | Batch 010 | Train Acc: 0.9600 | Train Loss: 0.0804 | Time: 0.2388\n",
            "Epoch 00002 | Batch 011 | Train Acc: 0.9800 | Train Loss: 0.0263 | Time: 0.2438\n",
            "Epoch 00002 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0056 | Time: 0.2669\n",
            "Epoch 00002 | Batch 013 | Train Acc: 0.9800 | Train Loss: 0.1330 | Time: 0.2411\n",
            "Epoch 00002 | Batch 014 | Train Acc: 0.9200 | Train Loss: 0.3981 | Time: 0.2306\n",
            "Epoch 00002 | Batch 015 | Train Acc: 0.9800 | Train Loss: 0.7303 | Time: 0.2372\n",
            "Epoch 00002 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2243\n",
            "Epoch 00002 | Valid Acc: 0.9913 | Valid loss: 0.0811 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.8209 | Time: 0.2335\n",
            "Epoch 00003 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0131 | Time: 0.2370\n",
            "Epoch 00003 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0037 | Time: 0.2371\n",
            "Epoch 00003 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0024 | Time: 0.2367\n",
            "Epoch 00003 | Batch 004 | Train Acc: 0.9600 | Train Loss: 0.0644 | Time: 0.2312\n",
            "Epoch 00003 | Batch 005 | Train Acc: 0.9800 | Train Loss: 0.0183 | Time: 0.2361\n",
            "Epoch 00003 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0121 | Time: 0.2384\n",
            "Epoch 00003 | Batch 007 | Train Acc: 0.9400 | Train Loss: 0.3782 | Time: 0.2392\n",
            "Epoch 00003 | Batch 008 | Train Acc: 0.9800 | Train Loss: 0.0400 | Time: 0.2339\n",
            "Epoch 00003 | Batch 009 | Train Acc: 0.9400 | Train Loss: 0.1464 | Time: 0.2367\n",
            "Epoch 00003 | Batch 010 | Train Acc: 0.9600 | Train Loss: 0.1873 | Time: 0.2692\n",
            "Epoch 00003 | Batch 011 | Train Acc: 0.9800 | Train Loss: 0.1347 | Time: 0.2408\n",
            "Epoch 00003 | Batch 012 | Train Acc: 0.9800 | Train Loss: 0.0424 | Time: 0.2350\n",
            "Epoch 00003 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0017 | Time: 0.2378\n",
            "Epoch 00003 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0004 | Time: 0.2314\n",
            "Epoch 00003 | Batch 015 | Train Acc: 0.9800 | Train Loss: 0.0396 | Time: 0.2311\n",
            "Epoch 00003 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2324\n",
            "Epoch 00003 | Valid Acc: 0.9975 | Valid loss: 0.0160 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2330\n",
            "Epoch 00004 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0110 | Time: 0.2381\n",
            "Epoch 00004 | Batch 002 | Train Acc: 0.9800 | Train Loss: 0.0261 | Time: 0.2362\n",
            "Epoch 00004 | Batch 003 | Train Acc: 0.9600 | Train Loss: 0.2374 | Time: 0.2367\n",
            "Epoch 00004 | Batch 004 | Train Acc: 0.9800 | Train Loss: 0.0258 | Time: 0.2344\n",
            "Epoch 00004 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2356\n",
            "Epoch 00004 | Batch 006 | Train Acc: 0.9800 | Train Loss: 0.0764 | Time: 0.2354\n",
            "Epoch 00004 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2387\n",
            "Epoch 00004 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0108 | Time: 0.2372\n",
            "Epoch 00004 | Batch 009 | Train Acc: 0.9800 | Train Loss: 0.0334 | Time: 0.2373\n",
            "Epoch 00004 | Batch 010 | Train Acc: 0.9600 | Train Loss: 0.0665 | Time: 0.2406\n",
            "Epoch 00004 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0143 | Time: 0.2356\n",
            "Epoch 00004 | Batch 012 | Train Acc: 0.9800 | Train Loss: 0.0421 | Time: 0.2529\n",
            "Epoch 00004 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2408\n",
            "Epoch 00004 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0064 | Time: 0.2395\n",
            "Epoch 00004 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0006 | Time: 0.2389\n",
            "Epoch 00004 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2382\n",
            "Epoch 00004 | Valid Acc: 1.0000 | Valid loss: 0.0003 | Time: 4.9094\n",
            "Epoch 00005 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2335\n",
            "Epoch 00005 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2347\n",
            "Epoch 00005 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2362\n",
            "Epoch 00005 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2401\n",
            "Epoch 00005 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2353\n",
            "Epoch 00005 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0011 | Time: 0.2384\n",
            "Epoch 00005 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2365\n",
            "Epoch 00005 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0004 | Time: 0.2388\n",
            "Epoch 00005 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2372\n",
            "Epoch 00005 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0011 | Time: 0.2336\n",
            "Epoch 00005 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0016 | Time: 0.2310\n",
            "Epoch 00005 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0027 | Time: 0.2297\n",
            "Epoch 00005 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2279\n",
            "Epoch 00005 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2359\n",
            "Epoch 00005 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2381\n",
            "Epoch 00005 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0070 | Time: 0.2388\n",
            "Epoch 00005 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2569\n",
            "Epoch 00005 | Valid Acc: 1.0000 | Valid loss: 0.0008 | Time: 4.8922\n",
            "Epoch 00006 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2339\n",
            "Epoch 00006 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2370\n",
            "Epoch 00006 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0007 | Time: 0.2355\n",
            "Epoch 00006 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0006 | Time: 0.2374\n",
            "Epoch 00006 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2385\n",
            "Epoch 00006 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2394\n",
            "Epoch 00006 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2368\n",
            "Epoch 00006 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2396\n",
            "Epoch 00006 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2362\n",
            "Epoch 00006 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2336\n",
            "Epoch 00006 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2333\n",
            "Epoch 00006 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2330\n",
            "Epoch 00006 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2303\n",
            "Epoch 00006 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2365\n",
            "Epoch 00006 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2702\n",
            "Epoch 00006 | Batch 015 | Train Acc: 0.9800 | Train Loss: 0.0163 | Time: 0.2360\n",
            "Epoch 00006 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2264\n",
            "Epoch 00006 | Valid Acc: 1.0000 | Valid loss: 0.0002 | Time: 4.8877\n",
            "Epoch 00007 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2368\n",
            "Epoch 00007 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2668\n",
            "Epoch 00007 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2541\n",
            "Epoch 00007 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2347\n",
            "Epoch 00007 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2387\n",
            "Epoch 00007 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2323\n",
            "Epoch 00007 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2365\n",
            "Epoch 00007 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2413\n",
            "Epoch 00007 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2383\n",
            "Epoch 00007 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2363\n",
            "Epoch 00007 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2374\n",
            "Epoch 00007 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2353\n",
            "Epoch 00007 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2355\n",
            "Epoch 00007 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2335\n",
            "Epoch 00007 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2380\n",
            "Epoch 00007 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2378\n",
            "Epoch 00007 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2256\n",
            "Epoch 00007 | Valid Acc: 1.0000 | Valid loss: 0.0000 | Time: 4.8915\n",
            "Epoch 00008 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2278\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2358\n",
            "Epoch 00008 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2369\n",
            "Epoch 00008 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2367\n",
            "Epoch 00008 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2417\n",
            "Epoch 00008 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2366\n",
            "Epoch 00008 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2367\n",
            "Epoch 00008 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2325\n",
            "Epoch 00008 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2391\n",
            "Epoch 00008 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2345\n",
            "Epoch 00008 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2369\n",
            "Epoch 00008 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2390\n",
            "Epoch 00008 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2393\n",
            "Epoch 00008 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2339\n",
            "Epoch 00008 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2348\n",
            "Epoch 00008 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2354\n",
            "Epoch 00008 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2279\n",
            "Epoch 00008 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8855\n",
            "Epoch 00009 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2339\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2370\n",
            "Epoch 00009 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2374\n",
            "Epoch 00009 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2345\n",
            "Epoch 00009 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2336\n",
            "Epoch 00009 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2344\n",
            "Epoch 00009 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2349\n",
            "Epoch 00009 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2364\n",
            "Epoch 00009 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2402\n",
            "Epoch 00009 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2414\n",
            "Epoch 00009 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2387\n",
            "Epoch 00009 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2385\n",
            "Epoch 00009 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2348\n",
            "Epoch 00009 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2325\n",
            "Epoch 00009 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2329\n",
            "Epoch 00009 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2335\n",
            "Epoch 00009 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2260\n",
            "Epoch 00009 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8804\n",
            "Epoch 00010 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2350\n",
            "Epoch 00010 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2499\n",
            "Epoch 00010 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2413\n",
            "Epoch 00010 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2385\n",
            "Epoch 00010 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2345\n",
            "Epoch 00010 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2406\n",
            "Epoch 00010 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2427\n",
            "Epoch 00010 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2359\n",
            "Epoch 00010 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2379\n",
            "Epoch 00010 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2371\n",
            "Epoch 00010 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2418\n",
            "Epoch 00010 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2375\n",
            "Epoch 00010 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2369\n",
            "Epoch 00010 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2351\n",
            "Epoch 00010 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2400\n",
            "Epoch 00010 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2441\n",
            "Epoch 00010 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2577\n",
            "Epoch 00010 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8889\n",
            "Epoch 00011 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2355\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2453\n",
            "Epoch 00011 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2390\n",
            "Epoch 00011 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2396\n",
            "Epoch 00011 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2506\n",
            "Epoch 00011 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2552\n",
            "Epoch 00011 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2425\n",
            "Epoch 00011 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2395\n",
            "Epoch 00011 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2415\n",
            "Epoch 00011 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2490\n",
            "Epoch 00011 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2361\n",
            "Epoch 00011 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2366\n",
            "Epoch 00011 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2415\n",
            "Epoch 00011 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2344\n",
            "Epoch 00011 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2662\n",
            "Epoch 00011 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2360\n",
            "Epoch 00011 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2241\n",
            "Epoch 00011 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8987\n",
            "Epoch 00012 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2350\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2662\n",
            "Epoch 00012 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2329\n",
            "Epoch 00012 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2312\n",
            "Epoch 00012 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2332\n",
            "Epoch 00012 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2359\n",
            "Epoch 00012 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2335\n",
            "Epoch 00012 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2357\n",
            "Epoch 00012 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2368\n",
            "Epoch 00012 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2320\n",
            "Epoch 00012 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2309\n",
            "Epoch 00012 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2324\n",
            "Epoch 00012 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2412\n",
            "Epoch 00012 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2330\n",
            "Epoch 00012 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2319\n",
            "Epoch 00012 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2308\n",
            "Epoch 00012 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2250\n",
            "Epoch 00012 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8924\n",
            "Epoch 00013 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2339\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2337\n",
            "Epoch 00013 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2366\n",
            "Epoch 00013 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2349\n",
            "Epoch 00013 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2382\n",
            "Epoch 00013 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2338\n",
            "Epoch 00013 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2370\n",
            "Epoch 00013 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2359\n",
            "Epoch 00013 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2329\n",
            "Epoch 00013 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2381\n",
            "Epoch 00013 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2342\n",
            "Epoch 00013 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2346\n",
            "Epoch 00013 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2353\n",
            "Epoch 00013 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2361\n",
            "Epoch 00013 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2342\n",
            "Epoch 00013 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2380\n",
            "Epoch 00013 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2352\n",
            "Epoch 00013 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8884\n",
            "Epoch 00014 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2324\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2399\n",
            "Epoch 00014 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2322\n",
            "Epoch 00014 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2324\n",
            "Epoch 00014 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2297\n",
            "Epoch 00014 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2354\n",
            "Epoch 00014 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2383\n",
            "Epoch 00014 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2353\n",
            "Epoch 00014 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2389\n",
            "Epoch 00014 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2338\n",
            "Epoch 00014 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2380\n",
            "Epoch 00014 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2365\n",
            "Epoch 00014 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2372\n",
            "Epoch 00014 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2388\n",
            "Epoch 00014 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2440\n",
            "Epoch 00014 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2344\n",
            "Epoch 00014 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2171\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8838\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2329\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2415\n",
            "Epoch 00015 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2381\n",
            "Epoch 00015 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2373\n",
            "Epoch 00015 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2334\n",
            "Epoch 00015 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2322\n",
            "Epoch 00015 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2419\n",
            "Epoch 00015 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2352\n",
            "Epoch 00015 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2353\n",
            "Epoch 00015 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2355\n",
            "Epoch 00015 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2353\n",
            "Epoch 00015 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2378\n",
            "Epoch 00015 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2368\n",
            "Epoch 00015 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2359\n",
            "Epoch 00015 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2309\n",
            "Epoch 00015 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2315\n",
            "Epoch 00015 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2584\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8839\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2372\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2386\n",
            "Epoch 00016 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2406\n",
            "Epoch 00016 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2429\n",
            "Epoch 00016 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2412\n",
            "Epoch 00016 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2356\n",
            "Epoch 00016 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2344\n",
            "Epoch 00016 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2345\n",
            "Epoch 00016 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2358\n",
            "Epoch 00016 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2395\n",
            "Epoch 00016 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0000 | Time: 0.2372\n",
            "Epoch 00016 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2335\n",
            "Epoch 00016 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2401\n",
            "Epoch 00016 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2343\n",
            "Epoch 00016 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2676\n",
            "Epoch 00016 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2342\n",
            "Epoch 00016 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0004 | Time: 0.2259\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8848\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2381\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2663\n",
            "Epoch 00017 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2342\n",
            "Epoch 00017 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2384\n",
            "Epoch 00017 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2385\n",
            "Epoch 00017 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2293\n",
            "Epoch 00017 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2321\n",
            "Epoch 00017 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2376\n",
            "Epoch 00017 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2353\n",
            "Epoch 00017 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2380\n",
            "Epoch 00017 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2346\n",
            "Epoch 00017 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2360\n",
            "Epoch 00017 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2419\n",
            "Epoch 00017 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2290\n",
            "Epoch 00017 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2344\n",
            "Epoch 00017 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2324\n",
            "Epoch 00017 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0009 | Time: 0.2306\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0002 | Time: 4.8837\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2589\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2473\n",
            "Epoch 00018 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2347\n",
            "Epoch 00018 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2353\n",
            "Epoch 00018 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2391\n",
            "Epoch 00018 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2368\n",
            "Epoch 00018 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2353\n",
            "Epoch 00018 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2368\n",
            "Epoch 00018 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0013 | Time: 0.2356\n",
            "Epoch 00018 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2338\n",
            "Epoch 00018 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2355\n",
            "Epoch 00018 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2369\n",
            "Epoch 00018 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2419\n",
            "Epoch 00018 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2367\n",
            "Epoch 00018 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2377\n",
            "Epoch 00018 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2343\n",
            "Epoch 00018 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2212\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8842\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2327\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2375\n",
            "Epoch 00019 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2425\n",
            "Epoch 00019 | Batch 003 | Train Acc: 1.0000 | Train Loss: 0.0003 | Time: 0.2339\n",
            "Epoch 00019 | Batch 004 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2404\n",
            "Epoch 00019 | Batch 005 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2397\n",
            "Epoch 00019 | Batch 006 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2397\n",
            "Epoch 00019 | Batch 007 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2408\n",
            "Epoch 00019 | Batch 008 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2401\n",
            "Epoch 00019 | Batch 009 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2382\n",
            "Epoch 00019 | Batch 010 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2399\n",
            "Epoch 00019 | Batch 011 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2419\n",
            "Epoch 00019 | Batch 012 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2383\n",
            "Epoch 00019 | Batch 013 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2379\n",
            "Epoch 00019 | Batch 014 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2395\n",
            "Epoch 00019 | Batch 015 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2397\n",
            "Epoch 00019 | Batch 016 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2239\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0001 | Time: 4.8854\n",
            "\n",
            "Total time: : 80.7838s | Batch time: : 0.2376s\n",
            " 71% 26733/37703 [52:34<6:20:11,  2.08s/it]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d aifb --testing --gpu 0 --fanout=4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGuZwmv5_Vf4",
        "outputId": "7ea0d32c-b2ec-417e-fae9-ce036a693461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='aifb', dropout=0, fanout=4, gpu=0, l2norm=0, lr=0.01, model_path=None, n_bases=-1, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.2700 | Train Loss: 1.4843 | Time: 0.2950\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.3750 | Train Loss: 1.2952 | Time: 0.2078\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.7214 | Valid loss: 1.0607 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.7500 | Train Loss: 1.0469 | Time: 0.2100\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.8000 | Train Loss: 1.0018 | Time: 0.2113\n",
            "Epoch 00001 | Valid Acc: 0.8714 | Valid loss: 0.8088 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.8500 | Train Loss: 0.8317 | Time: 0.2115\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.9000 | Train Loss: 0.6801 | Time: 0.2092\n",
            "Epoch 00002 | Valid Acc: 0.9071 | Valid loss: 0.6373 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.9200 | Train Loss: 0.6298 | Time: 0.2121\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.5846 | Time: 0.2162\n",
            "Epoch 00003 | Valid Acc: 0.9071 | Valid loss: 0.4920 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.9100 | Train Loss: 0.4902 | Time: 0.2179\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.9000 | Train Loss: 0.4256 | Time: 0.2146\n",
            "Epoch 00004 | Valid Acc: 0.9214 | Valid loss: 0.3765 | Time: 0.5213\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.9100 | Train Loss: 0.3828 | Time: 0.2128\n",
            "Epoch 00005 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.3072 | Time: 0.2137\n",
            "Epoch 00005 | Valid Acc: 0.9214 | Valid loss: 0.2961 | Time: 0.5189\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9200 | Train Loss: 0.3034 | Time: 0.2126\n",
            "Epoch 00006 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.2243 | Time: 0.2118\n",
            "Epoch 00006 | Valid Acc: 0.9214 | Valid loss: 0.2322 | Time: 0.5168\n",
            "Epoch 00007 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1916 | Time: 0.2124\n",
            "Epoch 00007 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.2917 | Time: 0.2133\n",
            "Epoch 00007 | Valid Acc: 0.9429 | Valid loss: 0.1949 | Time: 0.5234\n",
            "Epoch 00008 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.1482 | Time: 0.2113\n",
            "Epoch 00008 | Batch 001 | Train Acc: 0.9000 | Train Loss: 0.2771 | Time: 0.2107\n",
            "Epoch 00008 | Valid Acc: 0.9429 | Valid loss: 0.1681 | Time: 0.5208\n",
            "Epoch 00009 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.1333 | Time: 0.2160\n",
            "Epoch 00009 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.2239 | Time: 0.2143\n",
            "Epoch 00009 | Valid Acc: 0.9429 | Valid loss: 0.1464 | Time: 0.5204\n",
            "Epoch 00010 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.1009 | Time: 0.2184\n",
            "Epoch 00010 | Batch 001 | Train Acc: 0.9000 | Train Loss: 0.2411 | Time: 0.2152\n",
            "Epoch 00010 | Valid Acc: 0.9429 | Valid loss: 0.1301 | Time: 0.5250\n",
            "Epoch 00011 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1197 | Time: 0.2110\n",
            "Epoch 00011 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1371 | Time: 0.2115\n",
            "Epoch 00011 | Valid Acc: 0.9429 | Valid loss: 0.1151 | Time: 0.5233\n",
            "Epoch 00012 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1198 | Time: 0.2152\n",
            "Epoch 00012 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0921 | Time: 0.2148\n",
            "Epoch 00012 | Valid Acc: 0.9643 | Valid loss: 0.1022 | Time: 0.5229\n",
            "Epoch 00013 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.1117 | Time: 0.2171\n",
            "Epoch 00013 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.0833 | Time: 0.2145\n",
            "Epoch 00013 | Valid Acc: 0.9714 | Valid loss: 0.0894 | Time: 0.5229\n",
            "Epoch 00014 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.1150 | Time: 0.2132\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0267 | Time: 0.2121\n",
            "Epoch 00014 | Valid Acc: 0.9786 | Valid loss: 0.0834 | Time: 0.5224\n",
            "Epoch 00015 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.1083 | Time: 0.2148\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0130 | Time: 0.2490\n",
            "Epoch 00015 | Valid Acc: 0.9786 | Valid loss: 0.0754 | Time: 0.5250\n",
            "Epoch 00016 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0848 | Time: 0.2124\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0513 | Time: 0.2128\n",
            "Epoch 00016 | Valid Acc: 0.9857 | Valid loss: 0.0680 | Time: 0.5243\n",
            "Epoch 00017 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0821 | Time: 0.2136\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0334 | Time: 0.2156\n",
            "Epoch 00017 | Valid Acc: 0.9857 | Valid loss: 0.0609 | Time: 0.5238\n",
            "Epoch 00018 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0425 | Time: 0.2419\n",
            "Epoch 00018 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.1007 | Time: 0.2139\n",
            "Epoch 00018 | Valid Acc: 0.9857 | Valid loss: 0.0548 | Time: 0.5252\n",
            "Epoch 00019 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0527 | Time: 0.2121\n",
            "Epoch 00019 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0548 | Time: 0.2094\n",
            "Epoch 00019 | Valid Acc: 0.9857 | Valid loss: 0.0475 | Time: 0.5242\n",
            "\n",
            "Total time: : 8.6726s | Batch time: : 0.2168s\n",
            "100% 73/73 [00:08<00:00,  8.32it/s]\n",
            "100% 73/73 [00:09<00:00,  7.89it/s]\n",
            "Test Acc: 0.9167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d aifb --testing --gpu 0 --fanout=16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndMKHEuN_b37",
        "outputId": "d619df5e-019c-4d78-9f52-25bb07c9925a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='aifb', dropout=0, fanout=16, gpu=0, l2norm=0, lr=0.01, model_path=None, n_bases=-1, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.4700 | Train Loss: 1.3461 | Time: 0.2200\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.7250 | Train Loss: 1.1549 | Time: 0.2102\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.8429 | Valid loss: 0.9925 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.8500 | Train Loss: 0.9928 | Time: 0.2142\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.8500 | Train Loss: 0.8563 | Time: 0.2119\n",
            "Epoch 00001 | Valid Acc: 0.9071 | Valid loss: 0.7296 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.9200 | Train Loss: 0.6928 | Time: 0.2125\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.8750 | Train Loss: 0.7025 | Time: 0.4457\n",
            "Epoch 00002 | Valid Acc: 0.9143 | Valid loss: 0.5211 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.8800 | Train Loss: 0.5382 | Time: 0.2132\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.3811 | Time: 0.2170\n",
            "Epoch 00003 | Valid Acc: 0.9143 | Valid loss: 0.3743 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.9100 | Train Loss: 0.3935 | Time: 0.2130\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.2865 | Time: 0.2154\n",
            "Epoch 00004 | Valid Acc: 0.9143 | Valid loss: 0.2858 | Time: 0.5200\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.9000 | Train Loss: 0.3273 | Time: 0.2195\n",
            "Epoch 00005 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1630 | Time: 0.2160\n",
            "Epoch 00005 | Valid Acc: 0.9214 | Valid loss: 0.2352 | Time: 0.5257\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9500 | Train Loss: 0.1696 | Time: 0.2089\n",
            "Epoch 00006 | Batch 001 | Train Acc: 0.8750 | Train Loss: 0.3749 | Time: 0.2134\n",
            "Epoch 00006 | Valid Acc: 0.9357 | Valid loss: 0.1933 | Time: 0.5222\n",
            "Epoch 00007 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.1345 | Time: 0.2117\n",
            "Epoch 00007 | Batch 001 | Train Acc: 0.8750 | Train Loss: 0.3358 | Time: 0.2178\n",
            "Epoch 00007 | Valid Acc: 0.9429 | Valid loss: 0.1676 | Time: 0.5296\n",
            "Epoch 00008 | Batch 000 | Train Acc: 0.9200 | Train Loss: 0.2173 | Time: 0.2151\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0240 | Time: 0.2238\n",
            "Epoch 00008 | Valid Acc: 0.9429 | Valid loss: 0.1427 | Time: 0.5305\n",
            "Epoch 00009 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.1509 | Time: 0.2210\n",
            "Epoch 00009 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1219 | Time: 0.2181\n",
            "Epoch 00009 | Valid Acc: 0.9500 | Valid loss: 0.1262 | Time: 0.5317\n",
            "Epoch 00010 | Batch 000 | Train Acc: 0.9300 | Train Loss: 0.1643 | Time: 0.2184\n",
            "Epoch 00010 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0247 | Time: 0.2321\n",
            "Epoch 00010 | Valid Acc: 0.9714 | Valid loss: 0.1132 | Time: 0.5383\n",
            "Epoch 00011 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.1273 | Time: 0.2165\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0722 | Time: 0.2162\n",
            "Epoch 00011 | Valid Acc: 0.9714 | Valid loss: 0.1025 | Time: 0.5367\n",
            "Epoch 00012 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.1151 | Time: 0.2129\n",
            "Epoch 00012 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0660 | Time: 0.2143\n",
            "Epoch 00012 | Valid Acc: 0.9714 | Valid loss: 0.0938 | Time: 0.5349\n",
            "Epoch 00013 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.1036 | Time: 0.2206\n",
            "Epoch 00013 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.0679 | Time: 0.2365\n",
            "Epoch 00013 | Valid Acc: 0.9714 | Valid loss: 0.0852 | Time: 0.5371\n",
            "Epoch 00014 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0551 | Time: 0.2143\n",
            "Epoch 00014 | Batch 001 | Train Acc: 0.9250 | Train Loss: 0.1554 | Time: 0.2152\n",
            "Epoch 00014 | Valid Acc: 0.9714 | Valid loss: 0.0781 | Time: 0.5360\n",
            "Epoch 00015 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0669 | Time: 0.2164\n",
            "Epoch 00015 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1014 | Time: 0.2559\n",
            "Epoch 00015 | Valid Acc: 0.9714 | Valid loss: 0.0708 | Time: 0.5389\n",
            "Epoch 00016 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0556 | Time: 0.2141\n",
            "Epoch 00016 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.1032 | Time: 0.2244\n",
            "Epoch 00016 | Valid Acc: 0.9786 | Valid loss: 0.0629 | Time: 0.5384\n",
            "Epoch 00017 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0666 | Time: 0.2163\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0543 | Time: 0.2155\n",
            "Epoch 00017 | Valid Acc: 0.9857 | Valid loss: 0.0556 | Time: 0.5375\n",
            "Epoch 00018 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0343 | Time: 0.2456\n",
            "Epoch 00018 | Batch 001 | Train Acc: 0.9750 | Train Loss: 0.1042 | Time: 0.2155\n",
            "Epoch 00018 | Valid Acc: 0.9857 | Valid loss: 0.0508 | Time: 0.5386\n",
            "Epoch 00019 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0582 | Time: 0.2159\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0275 | Time: 0.2169\n",
            "Epoch 00019 | Valid Acc: 0.9857 | Valid loss: 0.0438 | Time: 0.5377\n",
            "\n",
            "Total time: : 8.9712s | Batch time: : 0.2243s\n",
            "100% 73/73 [00:08<00:00,  8.29it/s]\n",
            "100% 73/73 [00:09<00:00,  7.78it/s]\n",
            "Test Acc: 0.9722\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d mutag --l2norm 5e-4 --testing --gpu 0 --fanout=4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3InnOQ07AaMJ",
        "outputId": "4227a9a4-6ed0-4fa9-e045-2fb16a0abb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='mutag', dropout=0, fanout=4, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=-1, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.5700 | Train Loss: 0.6826 | Time: 0.1201\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.6100 | Train Loss: 0.6715 | Time: 0.1141\n",
            "Epoch 00000 | Batch 002 | Train Acc: 0.6667 | Train Loss: 0.6380 | Time: 0.1136\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.6103 | Valid loss: 0.6145 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.5800 | Train Loss: 0.6400 | Time: 0.1086\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.6100 | Train Loss: 0.6274 | Time: 0.1128\n",
            "Epoch 00001 | Batch 002 | Train Acc: 0.6528 | Train Loss: 0.5432 | Time: 0.1079\n",
            "Epoch 00001 | Valid Acc: 0.6985 | Valid loss: 0.5263 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.6800 | Train Loss: 0.5517 | Time: 0.1102\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.8500 | Train Loss: 0.4655 | Time: 0.1140\n",
            "Epoch 00002 | Batch 002 | Train Acc: 0.9028 | Train Loss: 0.4734 | Time: 0.1078\n",
            "Epoch 00002 | Valid Acc: 0.9449 | Valid loss: 0.4392 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.9300 | Train Loss: 0.4362 | Time: 0.1142\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.3855 | Time: 0.1101\n",
            "Epoch 00003 | Batch 002 | Train Acc: 0.9583 | Train Loss: 0.3800 | Time: 0.1076\n",
            "Epoch 00003 | Valid Acc: 0.9632 | Valid loss: 0.3099 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.3379 | Time: 0.1075\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.9600 | Train Loss: 0.2720 | Time: 0.1100\n",
            "Epoch 00004 | Batch 002 | Train Acc: 0.8194 | Train Loss: 0.3406 | Time: 0.1092\n",
            "Epoch 00004 | Valid Acc: 0.8860 | Valid loss: 0.2751 | Time: 0.3985\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.8800 | Train Loss: 0.2929 | Time: 0.1091\n",
            "Epoch 00005 | Batch 001 | Train Acc: 0.8700 | Train Loss: 0.2633 | Time: 0.1158\n",
            "Epoch 00005 | Batch 002 | Train Acc: 0.9306 | Train Loss: 0.1917 | Time: 0.1189\n",
            "Epoch 00005 | Valid Acc: 0.9853 | Valid loss: 0.1610 | Time: 0.4086\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.1518 | Time: 0.1123\n",
            "Epoch 00006 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.1392 | Time: 0.1110\n",
            "Epoch 00006 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.1030 | Time: 0.1110\n",
            "Epoch 00006 | Valid Acc: 0.9853 | Valid loss: 0.1158 | Time: 0.4115\n",
            "Epoch 00007 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.1057 | Time: 0.1209\n",
            "Epoch 00007 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0991 | Time: 0.1094\n",
            "Epoch 00007 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0830 | Time: 0.1414\n",
            "Epoch 00007 | Valid Acc: 0.9890 | Valid loss: 0.0817 | Time: 0.4212\n",
            "Epoch 00008 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0675 | Time: 0.1103\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0762 | Time: 0.1098\n",
            "Epoch 00008 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0470 | Time: 0.1109\n",
            "Epoch 00008 | Valid Acc: 1.0000 | Valid loss: 0.0384 | Time: 0.4184\n",
            "Epoch 00009 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0474 | Time: 0.1085\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0401 | Time: 0.1112\n",
            "Epoch 00009 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0263 | Time: 0.1105\n",
            "Epoch 00009 | Valid Acc: 0.9963 | Valid loss: 0.0441 | Time: 0.4161\n",
            "Epoch 00010 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0291 | Time: 0.1119\n",
            "Epoch 00010 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0366 | Time: 0.1104\n",
            "Epoch 00010 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0619 | Time: 0.1159\n",
            "Epoch 00010 | Valid Acc: 1.0000 | Valid loss: 0.0459 | Time: 0.4158\n",
            "Epoch 00011 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0563 | Time: 0.1117\n",
            "Epoch 00011 | Batch 001 | Train Acc: 0.9900 | Train Loss: 0.0382 | Time: 0.1117\n",
            "Epoch 00011 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0279 | Time: 0.1117\n",
            "Epoch 00011 | Valid Acc: 1.0000 | Valid loss: 0.0219 | Time: 0.4153\n",
            "Epoch 00012 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0225 | Time: 0.1105\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0152 | Time: 0.1122\n",
            "Epoch 00012 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0134 | Time: 0.1121\n",
            "Epoch 00012 | Valid Acc: 1.0000 | Valid loss: 0.0097 | Time: 0.4147\n",
            "Epoch 00013 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0087 | Time: 0.1162\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0105 | Time: 0.1185\n",
            "Epoch 00013 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0090 | Time: 0.1118\n",
            "Epoch 00013 | Valid Acc: 1.0000 | Valid loss: 0.0098 | Time: 0.4160\n",
            "Epoch 00014 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0111 | Time: 0.1085\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0094 | Time: 0.1095\n",
            "Epoch 00014 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0089 | Time: 0.1100\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0109 | Time: 0.4149\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0131 | Time: 0.1140\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0096 | Time: 0.1139\n",
            "Epoch 00015 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0090 | Time: 0.1120\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0133 | Time: 0.4154\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0204 | Time: 0.1184\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0175 | Time: 0.1116\n",
            "Epoch 00016 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0238 | Time: 0.1380\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0050 | Time: 0.4178\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0055 | Time: 0.1088\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0055 | Time: 0.1100\n",
            "Epoch 00017 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0038 | Time: 0.1089\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0040 | Time: 0.4167\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0052 | Time: 0.1086\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0084 | Time: 0.1091\n",
            "Epoch 00018 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0050 | Time: 0.1101\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0066 | Time: 0.4159\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0070 | Time: 0.1116\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0058 | Time: 0.1139\n",
            "Epoch 00019 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0080 | Time: 0.1121\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0047 | Time: 0.4157\n",
            "\n",
            "Total time: : 6.7616s | Batch time: : 0.1127s\n",
            "100% 272/272 [00:15<00:00, 17.06it/s]\n",
            "100% 272/272 [00:17<00:00, 15.92it/s]\n",
            "Test Acc: 0.6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d mutag --l2norm 5e-4 --testing --gpu 0 --fanout=16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7AuNa5sAb8L",
        "outputId": "6eab3319-d748-4faa-bd0e-599180339868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='mutag', dropout=0, fanout=16, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=-1, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.4100 | Train Loss: 0.7001 | Time: 0.1265\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.6700 | Train Loss: 0.6591 | Time: 0.1188\n",
            "Epoch 00000 | Batch 002 | Train Acc: 0.6250 | Train Loss: 0.6528 | Time: 0.1160\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.6140 | Valid loss: 0.6157 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.5700 | Train Loss: 0.6597 | Time: 0.1179\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.6300 | Train Loss: 0.5763 | Time: 0.1132\n",
            "Epoch 00001 | Batch 002 | Train Acc: 0.6528 | Train Loss: 0.5609 | Time: 0.1182\n",
            "Epoch 00001 | Valid Acc: 0.6618 | Valid loss: 0.5419 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.6100 | Train Loss: 0.5794 | Time: 0.1204\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.7900 | Train Loss: 0.4742 | Time: 0.1167\n",
            "Epoch 00002 | Batch 002 | Train Acc: 0.8056 | Train Loss: 0.4812 | Time: 0.1191\n",
            "Epoch 00002 | Valid Acc: 0.8897 | Valid loss: 0.4296 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.8800 | Train Loss: 0.4422 | Time: 0.1155\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.9500 | Train Loss: 0.3767 | Time: 0.1168\n",
            "Epoch 00003 | Batch 002 | Train Acc: 0.9722 | Train Loss: 0.3723 | Time: 0.1154\n",
            "Epoch 00003 | Valid Acc: 0.9890 | Valid loss: 0.3088 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.3212 | Time: 0.1135\n",
            "Epoch 00004 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.2678 | Time: 0.1121\n",
            "Epoch 00004 | Batch 002 | Train Acc: 0.9861 | Train Loss: 0.2469 | Time: 0.1131\n",
            "Epoch 00004 | Valid Acc: 1.0000 | Valid loss: 0.2007 | Time: 0.4273\n",
            "Epoch 00005 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.2056 | Time: 0.1164\n",
            "Epoch 00005 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.1694 | Time: 0.1175\n",
            "Epoch 00005 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.1516 | Time: 0.1153\n",
            "Epoch 00005 | Valid Acc: 0.9963 | Valid loss: 0.1211 | Time: 0.4333\n",
            "Epoch 00006 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.1100 | Time: 0.1172\n",
            "Epoch 00006 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.1027 | Time: 0.1149\n",
            "Epoch 00006 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0918 | Time: 0.1144\n",
            "Epoch 00006 | Valid Acc: 1.0000 | Valid loss: 0.0692 | Time: 0.4340\n",
            "Epoch 00007 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0748 | Time: 0.1131\n",
            "Epoch 00007 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0618 | Time: 0.1171\n",
            "Epoch 00007 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0394 | Time: 0.1456\n",
            "Epoch 00007 | Valid Acc: 1.0000 | Valid loss: 0.0387 | Time: 0.4413\n",
            "Epoch 00008 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0368 | Time: 0.1126\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0300 | Time: 0.1158\n",
            "Epoch 00008 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0317 | Time: 0.1123\n",
            "Epoch 00008 | Valid Acc: 1.0000 | Valid loss: 0.0230 | Time: 0.4392\n",
            "Epoch 00009 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0197 | Time: 0.1161\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0228 | Time: 0.1193\n",
            "Epoch 00009 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0174 | Time: 0.1127\n",
            "Epoch 00009 | Valid Acc: 1.0000 | Valid loss: 0.0155 | Time: 0.4398\n",
            "Epoch 00010 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0148 | Time: 0.1147\n",
            "Epoch 00010 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0137 | Time: 0.1143\n",
            "Epoch 00010 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0123 | Time: 0.1140\n",
            "Epoch 00010 | Valid Acc: 1.0000 | Valid loss: 0.0109 | Time: 0.4382\n",
            "Epoch 00011 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0116 | Time: 0.1177\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0102 | Time: 0.1174\n",
            "Epoch 00011 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0094 | Time: 0.1133\n",
            "Epoch 00011 | Valid Acc: 1.0000 | Valid loss: 0.0088 | Time: 0.4382\n",
            "Epoch 00012 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0098 | Time: 0.1129\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0074 | Time: 0.1212\n",
            "Epoch 00012 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0085 | Time: 0.1183\n",
            "Epoch 00012 | Valid Acc: 1.0000 | Valid loss: 0.0073 | Time: 0.4385\n",
            "Epoch 00013 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0072 | Time: 0.1116\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0075 | Time: 0.1116\n",
            "Epoch 00013 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0070 | Time: 0.1119\n",
            "Epoch 00013 | Valid Acc: 1.0000 | Valid loss: 0.0065 | Time: 0.4369\n",
            "Epoch 00014 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0063 | Time: 0.1114\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0064 | Time: 0.1152\n",
            "Epoch 00014 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0067 | Time: 0.1267\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0059 | Time: 0.4372\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0061 | Time: 0.1146\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0056 | Time: 0.1129\n",
            "Epoch 00015 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0054 | Time: 0.1186\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0056 | Time: 0.4369\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0056 | Time: 0.1174\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0049 | Time: 0.1159\n",
            "Epoch 00016 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0056 | Time: 0.1486\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0049 | Time: 0.4393\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0048 | Time: 0.1117\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0051 | Time: 0.1105\n",
            "Epoch 00017 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0046 | Time: 0.1109\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0046 | Time: 0.4377\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0045 | Time: 0.1110\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0048 | Time: 0.1142\n",
            "Epoch 00018 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0043 | Time: 0.1129\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0042 | Time: 0.4362\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0040 | Time: 0.1148\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0048 | Time: 0.1177\n",
            "Epoch 00019 | Batch 002 | Train Acc: 1.0000 | Train Loss: 0.0039 | Time: 0.1154\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0039 | Time: 0.4361\n",
            "\n",
            "Total time: : 6.9920s | Batch time: : 0.1165s\n",
            "100% 272/272 [00:15<00:00, 17.04it/s]\n",
            "100% 272/272 [00:17<00:00, 15.91it/s]\n",
            "Test Acc: 0.7500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d bgs --l2norm 5e-4 --n-bases 40 --testing --gpu 0 --fanout=8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqLBcVZWEBZB",
        "outputId": "044a9ac9-a4cd-4d29-9e08-9fc503c47c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='bgs', dropout=0, fanout=8, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=40, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.5500 | Train Loss: 0.6952 | Time: 0.2470\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.6471 | Train Loss: 0.6079 | Time: 0.2361\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.7863 | Valid loss: 0.3856 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.8000 | Train Loss: 0.3762 | Time: 0.2392\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.7647 | Train Loss: 0.3641 | Time: 0.2442\n",
            "Epoch 00001 | Valid Acc: 0.9231 | Valid loss: 0.2192 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.9400 | Train Loss: 0.2098 | Time: 0.2415\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.2157 | Time: 0.2412\n",
            "Epoch 00002 | Valid Acc: 0.9744 | Valid loss: 0.1598 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.1642 | Time: 0.2374\n",
            "Epoch 00003 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.1225 | Time: 0.2346\n",
            "Epoch 00003 | Valid Acc: 1.0000 | Valid loss: 0.1007 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.1106 | Time: 0.2359\n",
            "Epoch 00004 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0294 | Time: 0.2360\n",
            "Epoch 00004 | Valid Acc: 0.9744 | Valid loss: 0.0677 | Time: 0.6719\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0702 | Time: 0.2476\n",
            "Epoch 00005 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0469 | Time: 0.2412\n",
            "Epoch 00005 | Valid Acc: 0.9744 | Valid loss: 0.0630 | Time: 0.6835\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0591 | Time: 0.2437\n",
            "Epoch 00006 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.0732 | Time: 0.2386\n",
            "Epoch 00006 | Valid Acc: 0.9829 | Valid loss: 0.0417 | Time: 0.6930\n",
            "Epoch 00007 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0475 | Time: 0.2462\n",
            "Epoch 00007 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0158 | Time: 0.2517\n",
            "Epoch 00007 | Valid Acc: 1.0000 | Valid loss: 0.0264 | Time: 0.6948\n",
            "Epoch 00008 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0249 | Time: 0.2594\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0440 | Time: 0.2427\n",
            "Epoch 00008 | Valid Acc: 1.0000 | Valid loss: 0.0230 | Time: 0.7032\n",
            "Epoch 00009 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0265 | Time: 0.2393\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0034 | Time: 0.2394\n",
            "Epoch 00009 | Valid Acc: 1.0000 | Valid loss: 0.0153 | Time: 0.6995\n",
            "Epoch 00010 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0113 | Time: 0.2368\n",
            "Epoch 00010 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0310 | Time: 0.2366\n",
            "Epoch 00010 | Valid Acc: 1.0000 | Valid loss: 0.0104 | Time: 0.6955\n",
            "Epoch 00011 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0099 | Time: 0.2559\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0090 | Time: 0.2372\n",
            "Epoch 00011 | Valid Acc: 1.0000 | Valid loss: 0.0074 | Time: 0.6951\n",
            "Epoch 00012 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0074 | Time: 0.2415\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0058 | Time: 0.2380\n",
            "Epoch 00012 | Valid Acc: 1.0000 | Valid loss: 0.0060 | Time: 0.6933\n",
            "Epoch 00013 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0063 | Time: 0.2415\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0021 | Time: 0.2407\n",
            "Epoch 00013 | Valid Acc: 1.0000 | Valid loss: 0.0048 | Time: 0.6951\n",
            "Epoch 00014 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0032 | Time: 0.2397\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0167 | Time: 0.2446\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0036 | Time: 0.6940\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0041 | Time: 0.2426\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2418\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0023 | Time: 0.6932\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0027 | Time: 0.2433\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0005 | Time: 0.2423\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0017 | Time: 0.6927\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0020 | Time: 0.2423\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0001 | Time: 0.2395\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0013 | Time: 0.6920\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0012 | Time: 0.2454\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0023 | Time: 0.2677\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0012 | Time: 0.6938\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0013 | Time: 0.2472\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0002 | Time: 0.2390\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0012 | Time: 0.6933\n",
            "\n",
            "Total time: : 9.7057s | Batch time: : 0.2426s\n",
            "100% 949/949 [02:35<00:00,  6.11it/s]\n",
            "100% 949/949 [02:42<00:00,  5.82it/s]\n",
            "Test Acc: 0.9310\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_classify_mb.py -d bgs --l2norm 5e-4 --n-bases 40 --testing --gpu 0 --fanout=16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLCncAzwEG1s",
        "outputId": "43c640d7-3ee3-4dbc-a625-9e4613fa0199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=100, data_cpu=False, dataset='bgs', dropout=0, fanout=16, gpu=0, l2norm=0.0005, lr=0.01, model_path=None, n_bases=40, n_epochs=20, n_hidden=16, n_layers=2, use_self_loop=False, validation=False)\n",
            "Done loading data from cached files.\n",
            "start training...\n",
            "Epoch 00000 | Batch 000 | Train Acc: 0.6200 | Train Loss: 0.7769 | Time: 0.2517\n",
            "Epoch 00000 | Batch 001 | Train Acc: 0.4706 | Train Loss: 0.7381 | Time: 0.2456\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Epoch 00000 | Valid Acc: 0.5385 | Valid loss: 0.6448 | Time: nan\n",
            "Epoch 00001 | Batch 000 | Train Acc: 0.5700 | Train Loss: 0.6212 | Time: 0.2477\n",
            "Epoch 00001 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.4236 | Time: 0.2491\n",
            "Epoch 00001 | Valid Acc: 0.8889 | Valid loss: 0.2580 | Time: nan\n",
            "Epoch 00002 | Batch 000 | Train Acc: 0.8900 | Train Loss: 0.2557 | Time: 0.2707\n",
            "Epoch 00002 | Batch 001 | Train Acc: 0.8235 | Train Loss: 0.3226 | Time: 0.2823\n",
            "Epoch 00002 | Valid Acc: 0.8803 | Valid loss: 0.2734 | Time: nan\n",
            "Epoch 00003 | Batch 000 | Train Acc: 0.8900 | Train Loss: 0.2558 | Time: 0.2484\n",
            "Epoch 00003 | Batch 001 | Train Acc: 0.8824 | Train Loss: 0.3588 | Time: 0.2470\n",
            "Epoch 00003 | Valid Acc: 0.9060 | Valid loss: 0.1938 | Time: nan\n",
            "Epoch 00004 | Batch 000 | Train Acc: 0.9000 | Train Loss: 0.2056 | Time: 0.2459\n",
            "Epoch 00004 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.1096 | Time: 0.2486\n",
            "Epoch 00004 | Valid Acc: 0.9402 | Valid loss: 0.1211 | Time: 0.7013\n",
            "Epoch 00005 | Batch 000 | Train Acc: 0.9300 | Train Loss: 0.1311 | Time: 0.2516\n",
            "Epoch 00005 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0473 | Time: 0.2821\n",
            "Epoch 00005 | Valid Acc: 0.9915 | Valid loss: 0.1026 | Time: 0.7205\n",
            "Epoch 00006 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0997 | Time: 0.2727\n",
            "Epoch 00006 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.1288 | Time: 0.2770\n",
            "Epoch 00006 | Valid Acc: 0.9402 | Valid loss: 0.1043 | Time: 0.7498\n",
            "Epoch 00007 | Batch 000 | Train Acc: 0.9300 | Train Loss: 0.1163 | Time: 0.2780\n",
            "Epoch 00007 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0352 | Time: 0.2802\n",
            "Epoch 00007 | Valid Acc: 0.9915 | Valid loss: 0.0871 | Time: 0.7581\n",
            "Epoch 00008 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0850 | Time: 0.2521\n",
            "Epoch 00008 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0784 | Time: 0.2446\n",
            "Epoch 00008 | Valid Acc: 0.9915 | Valid loss: 0.0657 | Time: 0.7525\n",
            "Epoch 00009 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0599 | Time: 0.2441\n",
            "Epoch 00009 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0868 | Time: 0.2452\n",
            "Epoch 00009 | Valid Acc: 0.9829 | Valid loss: 0.0572 | Time: 0.7422\n",
            "Epoch 00010 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0518 | Time: 0.2458\n",
            "Epoch 00010 | Batch 001 | Train Acc: 0.9412 | Train Loss: 0.0929 | Time: 0.2458\n",
            "Epoch 00010 | Valid Acc: 0.9658 | Valid loss: 0.0546 | Time: 0.7352\n",
            "Epoch 00011 | Batch 000 | Train Acc: 0.9600 | Train Loss: 0.0613 | Time: 0.2466\n",
            "Epoch 00011 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0111 | Time: 0.2439\n",
            "Epoch 00011 | Valid Acc: 0.9744 | Valid loss: 0.0488 | Time: 0.7296\n",
            "Epoch 00012 | Batch 000 | Train Acc: 0.9700 | Train Loss: 0.0545 | Time: 0.2445\n",
            "Epoch 00012 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0161 | Time: 0.2424\n",
            "Epoch 00012 | Valid Acc: 0.9829 | Valid loss: 0.0397 | Time: 0.7250\n",
            "Epoch 00013 | Batch 000 | Train Acc: 0.9800 | Train Loss: 0.0409 | Time: 0.2446\n",
            "Epoch 00013 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0260 | Time: 0.2451\n",
            "Epoch 00013 | Valid Acc: 0.9915 | Valid loss: 0.0296 | Time: 0.7247\n",
            "Epoch 00014 | Batch 000 | Train Acc: 0.9900 | Train Loss: 0.0303 | Time: 0.2506\n",
            "Epoch 00014 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0219 | Time: 0.2637\n",
            "Epoch 00014 | Valid Acc: 1.0000 | Valid loss: 0.0222 | Time: 0.7238\n",
            "Epoch 00015 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0200 | Time: 0.2538\n",
            "Epoch 00015 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0278 | Time: 0.2495\n",
            "Epoch 00015 | Valid Acc: 1.0000 | Valid loss: 0.0177 | Time: 0.7228\n",
            "Epoch 00016 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0187 | Time: 0.2560\n",
            "Epoch 00016 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0126 | Time: 0.2527\n",
            "Epoch 00016 | Valid Acc: 1.0000 | Valid loss: 0.0152 | Time: 0.7231\n",
            "Epoch 00017 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0123 | Time: 0.2582\n",
            "Epoch 00017 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0328 | Time: 0.2555\n",
            "Epoch 00017 | Valid Acc: 1.0000 | Valid loss: 0.0132 | Time: 0.7237\n",
            "Epoch 00018 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0135 | Time: 0.2473\n",
            "Epoch 00018 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0076 | Time: 0.2826\n",
            "Epoch 00018 | Valid Acc: 1.0000 | Valid loss: 0.0104 | Time: 0.7243\n",
            "Epoch 00019 | Batch 000 | Train Acc: 1.0000 | Train Loss: 0.0092 | Time: 0.2473\n",
            "Epoch 00019 | Batch 001 | Train Acc: 1.0000 | Train Loss: 0.0156 | Time: 0.2449\n",
            "Epoch 00019 | Valid Acc: 1.0000 | Valid loss: 0.0082 | Time: 0.7225\n",
            "\n",
            "Total time: : 10.1846s | Batch time: : 0.2546s\n",
            "100% 949/949 [02:37<00:00,  6.02it/s]\n",
            "100% 949/949 [02:44<00:00,  5.78it/s]\n",
            "Test Acc: 0.9655\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dgl/examples/pytorch/rgcn-hetero-ogbn-mag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzY85rz10Mtx",
        "outputId": "3084571a-9963-4db8-aab5-710c9e0c07cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dgl/examples/pytorch/rgcn-hetero-ogbn-mag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fo2ski0nxf",
        "outputId": "ec2b8f2a-a448-4d6d-9a87-1d0a05d3c838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.64.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=1b780c1cdb599b7cdc855bbd5c6100b5aa29438f13c93d44c712a697af9f1601\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it29Ncqj0j05",
        "outputId": "9bc7ff9e-30ca-41fa-9cd3-6761789c7205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "## Training started ##\n",
            "Epoch: 001 Train Loss: 2.54 Valid Loss: 2.01 Train Accuracy: 0.3718 Valid Accuracy: 0.4664 Train Epoch Time: 83.31 Valid Epoch Time: 8.73\n",
            "Epoch: 002 Train Loss: 1.78 Valid Loss: 1.91 Train Accuracy: 0.5195 Valid Accuracy: 0.4861 Train Epoch Time: 79.72 Valid Epoch Time: 8.78\n",
            "Epoch: 003 Train Loss: 1.34 Valid Loss: 1.97 Train Accuracy: 0.6221 Valid Accuracy: 0.4871 Train Epoch Time: 78.43 Valid Epoch Time: 8.59\n",
            "Epoch: 004 Train Loss: 1.02 Valid Loss: 2.27 Train Accuracy: 0.7054 Valid Accuracy: 0.4671 Train Epoch Time: 78.47 Valid Epoch Time: 8.56\n",
            "Epoch: 005 Train Loss: 0.78 Valid Loss: 2.46 Train Accuracy: 0.7684 Valid Accuracy: 0.4648 Train Epoch Time: 78.40 Valid Epoch Time: 8.60\n",
            "Epoch: 006 Train Loss: 0.62 Valid Loss: 2.82 Train Accuracy: 0.8118 Valid Accuracy: 0.4524 Train Epoch Time: 78.42 Valid Epoch Time: 8.61\n",
            "Epoch: 007 Train Loss: 0.52 Valid Loss: 3.05 Train Accuracy: 0.8417 Valid Accuracy: 0.4517 Train Epoch Time: 78.53 Valid Epoch Time: 8.67\n",
            "Epoch: 008 Train Loss: 0.44 Valid Loss: 3.58 Train Accuracy: 0.8623 Valid Accuracy: 0.4422 Train Epoch Time: 78.90 Valid Epoch Time: 8.66\n",
            "Epoch: 009 Train Loss: 0.39 Valid Loss: 3.67 Train Accuracy: 0.8775 Valid Accuracy: 0.4471 Train Epoch Time: 78.65 Valid Epoch Time: 8.60\n",
            "Epoch: 010 Train Loss: 0.35 Valid Loss: 3.86 Train Accuracy: 0.8893 Valid Accuracy: 0.4414 Train Epoch Time: 78.93 Valid Epoch Time: 8.61\n",
            "## Training finished ##\n",
            "Best Epoch: 2 Train Loss: 1.78 Valid Loss: 1.91 Train Accuracy: 0.5195 Valid Accuracy: 0.4861\n",
            "## Test data validation ##\n",
            "Test Loss: 1.98 Test Accuracy: 0.4686 Test Epoch Time: 5.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entity_sample.py -d am --n-bases 40 --gpu 0 --fanout='35,35' --batch-size 64 --n-hidden 16 --use-self-loop --n-epochs=20 --dropout 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQb-Ojy8MUcO",
        "outputId": "043f8ca6-025a-476c-bcb5-dc282bcebefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Namespace(batch_size=64, dataset='am', dropout=0.7, fanout='35,35', gpu=0, n_bases=40, n_epochs=20, n_hidden=16, use_self_loop=True, wd=0.0005)\n",
            "Downloading /root/.dgl/am-hetero.zip from https://data.dgl.ai/dataset/rdf/am-hetero.zip...\n",
            "Extracting file to /root/.dgl/am-hetero\n",
            "Parsing file am_stripped05.nt ...\n",
            "Parsing file am_stripped02.nt ...\n",
            "Parsing file am_stripped08.nt ...\n",
            "Parsing file am_stripped09.nt ...\n",
            "Parsing file am_stripped04.nt ...\n",
            "Parsing file am_stripped07.nt ...\n",
            "Parsing file am_stripped00.nt ...\n",
            "Parsing file am_stripped06.nt ...\n",
            "Parsing file am_stripped01.nt ...\n",
            "Parsing file am_stripped03.nt ...\n",
            "Processed 0 tuples, found 0 valid tuples.\n",
            "Processed 10000 tuples, found 3813 valid tuples.\n",
            "Processed 20000 tuples, found 7685 valid tuples.\n",
            "Processed 30000 tuples, found 11556 valid tuples.\n",
            "Processed 40000 tuples, found 15394 valid tuples.\n",
            "Processed 50000 tuples, found 19186 valid tuples.\n",
            "Processed 60000 tuples, found 22943 valid tuples.\n",
            "Processed 70000 tuples, found 26786 valid tuples.\n",
            "Processed 80000 tuples, found 30574 valid tuples.\n",
            "Processed 90000 tuples, found 34416 valid tuples.\n",
            "Processed 100000 tuples, found 38241 valid tuples.\n",
            "Processed 110000 tuples, found 42010 valid tuples.\n",
            "Processed 120000 tuples, found 45794 valid tuples.\n",
            "Processed 130000 tuples, found 49687 valid tuples.\n",
            "Processed 140000 tuples, found 53481 valid tuples.\n",
            "Processed 150000 tuples, found 57240 valid tuples.\n",
            "Processed 160000 tuples, found 61071 valid tuples.\n",
            "Processed 170000 tuples, found 64908 valid tuples.\n",
            "Processed 180000 tuples, found 68764 valid tuples.\n",
            "Processed 190000 tuples, found 72606 valid tuples.\n",
            "Processed 200000 tuples, found 76420 valid tuples.\n",
            "Processed 210000 tuples, found 80192 valid tuples.\n",
            "Processed 220000 tuples, found 83997 valid tuples.\n",
            "Processed 230000 tuples, found 87749 valid tuples.\n",
            "Processed 240000 tuples, found 91510 valid tuples.\n",
            "Processed 250000 tuples, found 95239 valid tuples.\n",
            "Processed 260000 tuples, found 99068 valid tuples.\n",
            "Processed 270000 tuples, found 102929 valid tuples.\n",
            "Processed 280000 tuples, found 106737 valid tuples.\n",
            "Processed 290000 tuples, found 110550 valid tuples.\n",
            "Processed 300000 tuples, found 114417 valid tuples.\n",
            "Processed 310000 tuples, found 118178 valid tuples.\n",
            "Processed 320000 tuples, found 121922 valid tuples.\n",
            "Processed 330000 tuples, found 125673 valid tuples.\n",
            "Processed 340000 tuples, found 129508 valid tuples.\n",
            "Processed 350000 tuples, found 133409 valid tuples.\n",
            "Processed 360000 tuples, found 137206 valid tuples.\n",
            "Processed 370000 tuples, found 141213 valid tuples.\n",
            "Processed 380000 tuples, found 145014 valid tuples.\n",
            "Processed 390000 tuples, found 148792 valid tuples.\n",
            "Processed 400000 tuples, found 152642 valid tuples.\n",
            "Processed 410000 tuples, found 156605 valid tuples.\n",
            "Processed 420000 tuples, found 160467 valid tuples.\n",
            "Processed 430000 tuples, found 164322 valid tuples.\n",
            "Processed 440000 tuples, found 168218 valid tuples.\n",
            "Processed 450000 tuples, found 171991 valid tuples.\n",
            "Processed 460000 tuples, found 175803 valid tuples.\n",
            "Processed 470000 tuples, found 179615 valid tuples.\n",
            "Processed 480000 tuples, found 183438 valid tuples.\n",
            "Processed 490000 tuples, found 187278 valid tuples.\n",
            "Processed 500000 tuples, found 191087 valid tuples.\n",
            "Processed 510000 tuples, found 194860 valid tuples.\n",
            "Processed 520000 tuples, found 198677 valid tuples.\n",
            "Processed 530000 tuples, found 202363 valid tuples.\n",
            "Processed 540000 tuples, found 206192 valid tuples.\n",
            "Processed 550000 tuples, found 210147 valid tuples.\n",
            "Processed 560000 tuples, found 213933 valid tuples.\n",
            "Processed 570000 tuples, found 217727 valid tuples.\n",
            "Processed 580000 tuples, found 221600 valid tuples.\n",
            "Processed 590000 tuples, found 225461 valid tuples.\n",
            "Processed 600000 tuples, found 229307 valid tuples.\n",
            "Processed 610000 tuples, found 233152 valid tuples.\n",
            "Processed 620000 tuples, found 237009 valid tuples.\n",
            "Processed 630000 tuples, found 240757 valid tuples.\n",
            "Processed 640000 tuples, found 244634 valid tuples.\n",
            "Processed 650000 tuples, found 248451 valid tuples.\n",
            "Processed 660000 tuples, found 252221 valid tuples.\n",
            "Processed 670000 tuples, found 256028 valid tuples.\n",
            "Processed 680000 tuples, found 259892 valid tuples.\n",
            "Processed 690000 tuples, found 263806 valid tuples.\n",
            "Processed 700000 tuples, found 267718 valid tuples.\n",
            "Processed 710000 tuples, found 271480 valid tuples.\n",
            "Processed 720000 tuples, found 275284 valid tuples.\n",
            "Processed 730000 tuples, found 279023 valid tuples.\n",
            "Processed 740000 tuples, found 282822 valid tuples.\n",
            "Processed 750000 tuples, found 286566 valid tuples.\n",
            "Processed 760000 tuples, found 290411 valid tuples.\n",
            "Processed 770000 tuples, found 294245 valid tuples.\n",
            "Processed 780000 tuples, found 298131 valid tuples.\n",
            "Processed 790000 tuples, found 301976 valid tuples.\n",
            "Processed 800000 tuples, found 305836 valid tuples.\n",
            "Processed 810000 tuples, found 309636 valid tuples.\n",
            "Processed 820000 tuples, found 313436 valid tuples.\n",
            "Processed 830000 tuples, found 317241 valid tuples.\n",
            "Processed 840000 tuples, found 321068 valid tuples.\n",
            "Processed 850000 tuples, found 324898 valid tuples.\n",
            "Processed 860000 tuples, found 328683 valid tuples.\n",
            "Processed 870000 tuples, found 332550 valid tuples.\n",
            "Processed 880000 tuples, found 336283 valid tuples.\n",
            "Processed 890000 tuples, found 340099 valid tuples.\n",
            "Processed 900000 tuples, found 343937 valid tuples.\n",
            "Processed 910000 tuples, found 347804 valid tuples.\n",
            "Processed 920000 tuples, found 351578 valid tuples.\n",
            "Processed 930000 tuples, found 355387 valid tuples.\n",
            "Processed 940000 tuples, found 359135 valid tuples.\n",
            "Processed 950000 tuples, found 362920 valid tuples.\n",
            "Processed 960000 tuples, found 366745 valid tuples.\n",
            "Processed 970000 tuples, found 370573 valid tuples.\n",
            "Processed 980000 tuples, found 374410 valid tuples.\n",
            "Processed 990000 tuples, found 378206 valid tuples.\n",
            "Processed 1000000 tuples, found 382148 valid tuples.\n",
            "Processed 1010000 tuples, found 385962 valid tuples.\n",
            "Processed 1020000 tuples, found 389762 valid tuples.\n",
            "Processed 1030000 tuples, found 393565 valid tuples.\n",
            "Processed 1040000 tuples, found 397394 valid tuples.\n",
            "Processed 1050000 tuples, found 401168 valid tuples.\n",
            "Processed 1060000 tuples, found 404989 valid tuples.\n",
            "Processed 1070000 tuples, found 408787 valid tuples.\n",
            "Processed 1080000 tuples, found 412643 valid tuples.\n",
            "Processed 1090000 tuples, found 416527 valid tuples.\n",
            "Processed 1100000 tuples, found 420307 valid tuples.\n",
            "Processed 1110000 tuples, found 424138 valid tuples.\n",
            "Processed 1120000 tuples, found 428006 valid tuples.\n",
            "Processed 1130000 tuples, found 431806 valid tuples.\n",
            "Processed 1140000 tuples, found 435639 valid tuples.\n",
            "Processed 1150000 tuples, found 439516 valid tuples.\n",
            "Processed 1160000 tuples, found 443303 valid tuples.\n",
            "Processed 1170000 tuples, found 447040 valid tuples.\n",
            "Processed 1180000 tuples, found 450849 valid tuples.\n",
            "Processed 1190000 tuples, found 454690 valid tuples.\n",
            "Processed 1200000 tuples, found 458564 valid tuples.\n",
            "Processed 1210000 tuples, found 462483 valid tuples.\n",
            "Processed 1220000 tuples, found 466223 valid tuples.\n",
            "Processed 1230000 tuples, found 470010 valid tuples.\n",
            "Processed 1240000 tuples, found 473846 valid tuples.\n",
            "Processed 1250000 tuples, found 477651 valid tuples.\n",
            "Processed 1260000 tuples, found 481423 valid tuples.\n",
            "Processed 1270000 tuples, found 485222 valid tuples.\n",
            "Processed 1280000 tuples, found 489067 valid tuples.\n",
            "Processed 1290000 tuples, found 492934 valid tuples.\n",
            "Processed 1300000 tuples, found 496758 valid tuples.\n",
            "Processed 1310000 tuples, found 500539 valid tuples.\n",
            "Processed 1320000 tuples, found 504279 valid tuples.\n",
            "Processed 1330000 tuples, found 508026 valid tuples.\n",
            "Processed 1340000 tuples, found 511891 valid tuples.\n",
            "Processed 1350000 tuples, found 515709 valid tuples.\n",
            "Processed 1360000 tuples, found 519495 valid tuples.\n",
            "Processed 1370000 tuples, found 523343 valid tuples.\n",
            "Processed 1380000 tuples, found 527141 valid tuples.\n",
            "Processed 1390000 tuples, found 530918 valid tuples.\n",
            "Processed 1400000 tuples, found 534724 valid tuples.\n",
            "Processed 1410000 tuples, found 538553 valid tuples.\n",
            "Processed 1420000 tuples, found 542414 valid tuples.\n",
            "Processed 1430000 tuples, found 546290 valid tuples.\n",
            "Processed 1440000 tuples, found 550103 valid tuples.\n",
            "Processed 1450000 tuples, found 553883 valid tuples.\n",
            "Processed 1460000 tuples, found 557760 valid tuples.\n",
            "Processed 1470000 tuples, found 561616 valid tuples.\n",
            "Processed 1480000 tuples, found 565445 valid tuples.\n",
            "Processed 1490000 tuples, found 569276 valid tuples.\n",
            "Processed 1500000 tuples, found 573144 valid tuples.\n",
            "Processed 1510000 tuples, found 576975 valid tuples.\n",
            "Processed 1520000 tuples, found 580795 valid tuples.\n",
            "Processed 1530000 tuples, found 584641 valid tuples.\n",
            "Processed 1540000 tuples, found 588418 valid tuples.\n",
            "Processed 1550000 tuples, found 592257 valid tuples.\n",
            "Processed 1560000 tuples, found 596104 valid tuples.\n",
            "Processed 1570000 tuples, found 599942 valid tuples.\n",
            "Processed 1580000 tuples, found 603743 valid tuples.\n",
            "Processed 1590000 tuples, found 607542 valid tuples.\n",
            "Processed 1600000 tuples, found 611455 valid tuples.\n",
            "Processed 1610000 tuples, found 615280 valid tuples.\n",
            "Processed 1620000 tuples, found 619087 valid tuples.\n",
            "Processed 1630000 tuples, found 622897 valid tuples.\n",
            "Processed 1640000 tuples, found 626763 valid tuples.\n",
            "Processed 1650000 tuples, found 630612 valid tuples.\n",
            "Processed 1660000 tuples, found 634490 valid tuples.\n",
            "Processed 1670000 tuples, found 638318 valid tuples.\n",
            "Processed 1680000 tuples, found 642206 valid tuples.\n",
            "Processed 1690000 tuples, found 645930 valid tuples.\n",
            "Processed 1700000 tuples, found 649697 valid tuples.\n",
            "Processed 1710000 tuples, found 653517 valid tuples.\n",
            "Processed 1720000 tuples, found 657358 valid tuples.\n",
            "Processed 1730000 tuples, found 661072 valid tuples.\n",
            "Processed 1740000 tuples, found 664936 valid tuples.\n",
            "Processed 1750000 tuples, found 668830 valid tuples.\n",
            "Processed 1760000 tuples, found 672661 valid tuples.\n",
            "Processed 1770000 tuples, found 676388 valid tuples.\n",
            "Processed 1780000 tuples, found 680255 valid tuples.\n",
            "Processed 1790000 tuples, found 684094 valid tuples.\n",
            "Processed 1800000 tuples, found 687949 valid tuples.\n",
            "Processed 1810000 tuples, found 691691 valid tuples.\n",
            "Processed 1820000 tuples, found 695495 valid tuples.\n",
            "Processed 1830000 tuples, found 699304 valid tuples.\n",
            "Processed 1840000 tuples, found 703159 valid tuples.\n",
            "Processed 1850000 tuples, found 706899 valid tuples.\n",
            "Processed 1860000 tuples, found 710731 valid tuples.\n",
            "Processed 1870000 tuples, found 714497 valid tuples.\n",
            "Processed 1880000 tuples, found 718319 valid tuples.\n",
            "Processed 1890000 tuples, found 722113 valid tuples.\n",
            "Processed 1900000 tuples, found 725879 valid tuples.\n",
            "Processed 1910000 tuples, found 729650 valid tuples.\n",
            "Processed 1920000 tuples, found 733493 valid tuples.\n",
            "Processed 1930000 tuples, found 737311 valid tuples.\n",
            "Processed 1940000 tuples, found 741183 valid tuples.\n",
            "Processed 1950000 tuples, found 745032 valid tuples.\n",
            "Processed 1960000 tuples, found 748842 valid tuples.\n",
            "Processed 1970000 tuples, found 752617 valid tuples.\n",
            "Processed 1980000 tuples, found 756354 valid tuples.\n",
            "Processed 1990000 tuples, found 760191 valid tuples.\n",
            "Processed 2000000 tuples, found 764074 valid tuples.\n",
            "Processed 2010000 tuples, found 767934 valid tuples.\n",
            "Processed 2020000 tuples, found 771785 valid tuples.\n",
            "Processed 2030000 tuples, found 775627 valid tuples.\n",
            "Processed 2040000 tuples, found 779498 valid tuples.\n",
            "Processed 2050000 tuples, found 783313 valid tuples.\n",
            "Processed 2060000 tuples, found 787130 valid tuples.\n",
            "Processed 2070000 tuples, found 790949 valid tuples.\n",
            "Processed 2080000 tuples, found 794766 valid tuples.\n",
            "Processed 2090000 tuples, found 798619 valid tuples.\n",
            "Processed 2100000 tuples, found 802378 valid tuples.\n",
            "Processed 2110000 tuples, found 806249 valid tuples.\n",
            "Processed 2120000 tuples, found 810018 valid tuples.\n",
            "Processed 2130000 tuples, found 813868 valid tuples.\n",
            "Processed 2140000 tuples, found 817742 valid tuples.\n",
            "Processed 2150000 tuples, found 821649 valid tuples.\n",
            "Processed 2160000 tuples, found 825457 valid tuples.\n",
            "Processed 2170000 tuples, found 829233 valid tuples.\n",
            "Processed 2180000 tuples, found 833025 valid tuples.\n",
            "Processed 2190000 tuples, found 836836 valid tuples.\n",
            "Processed 2200000 tuples, found 840674 valid tuples.\n",
            "Processed 2210000 tuples, found 844501 valid tuples.\n",
            "Processed 2220000 tuples, found 848345 valid tuples.\n",
            "Processed 2230000 tuples, found 852204 valid tuples.\n",
            "Processed 2240000 tuples, found 855937 valid tuples.\n",
            "Processed 2250000 tuples, found 859629 valid tuples.\n",
            "Processed 2260000 tuples, found 863417 valid tuples.\n",
            "Processed 2270000 tuples, found 867158 valid tuples.\n",
            "Processed 2280000 tuples, found 870949 valid tuples.\n",
            "Processed 2290000 tuples, found 874645 valid tuples.\n",
            "Processed 2300000 tuples, found 878564 valid tuples.\n",
            "Processed 2310000 tuples, found 882323 valid tuples.\n",
            "Processed 2320000 tuples, found 886159 valid tuples.\n",
            "Processed 2330000 tuples, found 889943 valid tuples.\n",
            "Processed 2340000 tuples, found 893786 valid tuples.\n",
            "Processed 2350000 tuples, found 897611 valid tuples.\n",
            "Processed 2360000 tuples, found 901424 valid tuples.\n",
            "Processed 2370000 tuples, found 905252 valid tuples.\n",
            "Processed 2380000 tuples, found 909047 valid tuples.\n",
            "Processed 2390000 tuples, found 912839 valid tuples.\n",
            "Processed 2400000 tuples, found 916733 valid tuples.\n",
            "Processed 2410000 tuples, found 920545 valid tuples.\n",
            "Processed 2420000 tuples, found 924438 valid tuples.\n",
            "Processed 2430000 tuples, found 928296 valid tuples.\n",
            "Processed 2440000 tuples, found 932044 valid tuples.\n",
            "Processed 2450000 tuples, found 935914 valid tuples.\n",
            "Processed 2460000 tuples, found 939744 valid tuples.\n",
            "Processed 2470000 tuples, found 943588 valid tuples.\n",
            "Processed 2480000 tuples, found 947436 valid tuples.\n",
            "Processed 2490000 tuples, found 951199 valid tuples.\n",
            "Processed 2500000 tuples, found 955063 valid tuples.\n",
            "Processed 2510000 tuples, found 958768 valid tuples.\n",
            "Processed 2520000 tuples, found 962565 valid tuples.\n",
            "Processed 2530000 tuples, found 966399 valid tuples.\n",
            "Processed 2540000 tuples, found 970242 valid tuples.\n",
            "Processed 2550000 tuples, found 974076 valid tuples.\n",
            "Processed 2560000 tuples, found 977903 valid tuples.\n",
            "Processed 2570000 tuples, found 981715 valid tuples.\n",
            "Processed 2580000 tuples, found 985517 valid tuples.\n",
            "Processed 2590000 tuples, found 989412 valid tuples.\n",
            "Processed 2600000 tuples, found 993309 valid tuples.\n",
            "Processed 2610000 tuples, found 997216 valid tuples.\n",
            "Processed 2620000 tuples, found 1001063 valid tuples.\n",
            "Processed 2630000 tuples, found 1004942 valid tuples.\n",
            "Processed 2640000 tuples, found 1008753 valid tuples.\n",
            "Processed 2650000 tuples, found 1012627 valid tuples.\n",
            "Processed 2660000 tuples, found 1016421 valid tuples.\n",
            "Processed 2670000 tuples, found 1020259 valid tuples.\n",
            "Processed 2680000 tuples, found 1024070 valid tuples.\n",
            "Processed 2690000 tuples, found 1027949 valid tuples.\n",
            "Processed 2700000 tuples, found 1031793 valid tuples.\n",
            "Processed 2710000 tuples, found 1035550 valid tuples.\n",
            "Processed 2720000 tuples, found 1039313 valid tuples.\n",
            "Processed 2730000 tuples, found 1043099 valid tuples.\n",
            "Processed 2740000 tuples, found 1046929 valid tuples.\n",
            "Processed 2750000 tuples, found 1050762 valid tuples.\n",
            "Processed 2760000 tuples, found 1054590 valid tuples.\n",
            "Processed 2770000 tuples, found 1058372 valid tuples.\n",
            "Processed 2780000 tuples, found 1062133 valid tuples.\n",
            "Processed 2790000 tuples, found 1065954 valid tuples.\n",
            "Processed 2800000 tuples, found 1069764 valid tuples.\n",
            "Processed 2810000 tuples, found 1073580 valid tuples.\n",
            "Processed 2820000 tuples, found 1077368 valid tuples.\n",
            "Processed 2830000 tuples, found 1081160 valid tuples.\n",
            "Processed 2840000 tuples, found 1085023 valid tuples.\n",
            "Processed 2850000 tuples, found 1088872 valid tuples.\n",
            "Processed 2860000 tuples, found 1092599 valid tuples.\n",
            "Processed 2870000 tuples, found 1096368 valid tuples.\n",
            "Processed 2880000 tuples, found 1100129 valid tuples.\n",
            "Processed 2890000 tuples, found 1103918 valid tuples.\n",
            "Processed 2900000 tuples, found 1107789 valid tuples.\n",
            "Processed 2910000 tuples, found 1111572 valid tuples.\n",
            "Processed 2920000 tuples, found 1115376 valid tuples.\n",
            "Processed 2930000 tuples, found 1119150 valid tuples.\n",
            "Processed 2940000 tuples, found 1122906 valid tuples.\n",
            "Processed 2950000 tuples, found 1126694 valid tuples.\n",
            "Processed 2960000 tuples, found 1130484 valid tuples.\n",
            "Processed 2970000 tuples, found 1134307 valid tuples.\n",
            "Processed 2980000 tuples, found 1138050 valid tuples.\n",
            "Processed 2990000 tuples, found 1141837 valid tuples.\n",
            "Processed 3000000 tuples, found 1145743 valid tuples.\n",
            "Processed 3010000 tuples, found 1149613 valid tuples.\n",
            "Processed 3020000 tuples, found 1153415 valid tuples.\n",
            "Processed 3030000 tuples, found 1157203 valid tuples.\n",
            "Processed 3040000 tuples, found 1160987 valid tuples.\n",
            "Processed 3050000 tuples, found 1164832 valid tuples.\n",
            "Processed 3060000 tuples, found 1168588 valid tuples.\n",
            "Processed 3070000 tuples, found 1172355 valid tuples.\n",
            "Processed 3080000 tuples, found 1176281 valid tuples.\n",
            "Processed 3090000 tuples, found 1176498 valid tuples.\n",
            "Processed 3100000 tuples, found 1176498 valid tuples.\n",
            "Processed 3110000 tuples, found 1176498 valid tuples.\n",
            "Processed 3120000 tuples, found 1176498 valid tuples.\n",
            "Processed 3130000 tuples, found 1176498 valid tuples.\n",
            "Processed 3140000 tuples, found 1176498 valid tuples.\n",
            "Processed 3150000 tuples, found 1176498 valid tuples.\n",
            "Processed 3160000 tuples, found 1176498 valid tuples.\n",
            "Processed 3170000 tuples, found 1176498 valid tuples.\n",
            "Processed 3180000 tuples, found 1176498 valid tuples.\n",
            "Processed 3190000 tuples, found 1176498 valid tuples.\n",
            "Processed 3200000 tuples, found 1176498 valid tuples.\n",
            "Processed 3210000 tuples, found 1176498 valid tuples.\n",
            "Processed 3220000 tuples, found 1176498 valid tuples.\n",
            "Processed 3230000 tuples, found 1177442 valid tuples.\n",
            "Processed 3240000 tuples, found 1181442 valid tuples.\n",
            "Processed 3250000 tuples, found 1185442 valid tuples.\n",
            "Processed 3260000 tuples, found 1189442 valid tuples.\n",
            "Processed 3270000 tuples, found 1193442 valid tuples.\n",
            "Processed 3280000 tuples, found 1197442 valid tuples.\n",
            "Processed 3290000 tuples, found 1201442 valid tuples.\n",
            "Processed 3300000 tuples, found 1205442 valid tuples.\n",
            "Processed 3310000 tuples, found 1209442 valid tuples.\n",
            "Processed 3320000 tuples, found 1213442 valid tuples.\n",
            "Processed 3330000 tuples, found 1217442 valid tuples.\n",
            "Processed 3340000 tuples, found 1221442 valid tuples.\n",
            "Processed 3350000 tuples, found 1225442 valid tuples.\n",
            "Processed 3360000 tuples, found 1229442 valid tuples.\n",
            "Processed 3370000 tuples, found 1233442 valid tuples.\n",
            "Processed 3380000 tuples, found 1237442 valid tuples.\n",
            "Processed 3390000 tuples, found 1241442 valid tuples.\n",
            "Processed 3400000 tuples, found 1245442 valid tuples.\n",
            "Processed 3410000 tuples, found 1249442 valid tuples.\n",
            "Processed 3420000 tuples, found 1253442 valid tuples.\n",
            "Processed 3430000 tuples, found 1257442 valid tuples.\n",
            "Processed 3440000 tuples, found 1261442 valid tuples.\n",
            "Processed 3450000 tuples, found 1265442 valid tuples.\n",
            "Processed 3460000 tuples, found 1269442 valid tuples.\n",
            "Processed 3470000 tuples, found 1273442 valid tuples.\n",
            "Processed 3480000 tuples, found 1277442 valid tuples.\n",
            "Processed 3490000 tuples, found 1281442 valid tuples.\n",
            "Processed 3500000 tuples, found 1285442 valid tuples.\n",
            "Processed 3510000 tuples, found 1289442 valid tuples.\n",
            "Processed 3520000 tuples, found 1293442 valid tuples.\n",
            "Processed 3530000 tuples, found 1297442 valid tuples.\n",
            "Processed 3540000 tuples, found 1301442 valid tuples.\n",
            "Processed 3550000 tuples, found 1305442 valid tuples.\n",
            "Processed 3560000 tuples, found 1309442 valid tuples.\n",
            "Processed 3570000 tuples, found 1313442 valid tuples.\n",
            "Processed 3580000 tuples, found 1317442 valid tuples.\n",
            "Processed 3590000 tuples, found 1321442 valid tuples.\n",
            "Processed 3600000 tuples, found 1324607 valid tuples.\n",
            "Processed 3610000 tuples, found 1327008 valid tuples.\n",
            "Processed 3620000 tuples, found 1329508 valid tuples.\n",
            "Processed 3630000 tuples, found 1331944 valid tuples.\n",
            "Processed 3640000 tuples, found 1334433 valid tuples.\n",
            "Processed 3650000 tuples, found 1338734 valid tuples.\n",
            "Processed 3660000 tuples, found 1341650 valid tuples.\n",
            "Processed 3670000 tuples, found 1343578 valid tuples.\n",
            "Processed 3680000 tuples, found 1345238 valid tuples.\n",
            "Processed 3690000 tuples, found 1346569 valid tuples.\n",
            "Processed 3700000 tuples, found 1348737 valid tuples.\n",
            "Processed 3710000 tuples, found 1353113 valid tuples.\n",
            "Processed 3720000 tuples, found 1354962 valid tuples.\n",
            "Processed 3730000 tuples, found 1357736 valid tuples.\n",
            "Processed 3740000 tuples, found 1360200 valid tuples.\n",
            "Processed 3750000 tuples, found 1362661 valid tuples.\n",
            "Processed 3760000 tuples, found 1365127 valid tuples.\n",
            "Processed 3770000 tuples, found 1367591 valid tuples.\n",
            "Processed 3780000 tuples, found 1370034 valid tuples.\n",
            "Processed 3790000 tuples, found 1372568 valid tuples.\n",
            "Processed 3800000 tuples, found 1374889 valid tuples.\n",
            "Processed 3810000 tuples, found 1377357 valid tuples.\n",
            "Processed 3820000 tuples, found 1379734 valid tuples.\n",
            "Processed 3830000 tuples, found 1382108 valid tuples.\n",
            "Processed 3840000 tuples, found 1384508 valid tuples.\n",
            "Processed 3850000 tuples, found 1387100 valid tuples.\n",
            "Processed 3860000 tuples, found 1389561 valid tuples.\n",
            "Processed 3870000 tuples, found 1391897 valid tuples.\n",
            "Processed 3880000 tuples, found 1394296 valid tuples.\n",
            "Processed 3890000 tuples, found 1396747 valid tuples.\n",
            "Processed 3900000 tuples, found 1399117 valid tuples.\n",
            "Processed 3910000 tuples, found 1400627 valid tuples.\n",
            "Processed 3920000 tuples, found 1400627 valid tuples.\n",
            "Processed 3930000 tuples, found 1400627 valid tuples.\n",
            "Processed 3940000 tuples, found 1400627 valid tuples.\n",
            "Processed 3950000 tuples, found 1400627 valid tuples.\n",
            "Processed 3960000 tuples, found 1400627 valid tuples.\n",
            "Processed 3970000 tuples, found 1400627 valid tuples.\n",
            "Processed 3980000 tuples, found 1400824 valid tuples.\n",
            "Processed 3990000 tuples, found 1407879 valid tuples.\n",
            "Processed 4000000 tuples, found 1415028 valid tuples.\n",
            "Processed 4010000 tuples, found 1422318 valid tuples.\n",
            "Processed 4020000 tuples, found 1429633 valid tuples.\n",
            "Processed 4030000 tuples, found 1437330 valid tuples.\n",
            "Processed 4040000 tuples, found 1445583 valid tuples.\n",
            "Processed 4050000 tuples, found 1453387 valid tuples.\n",
            "Processed 4060000 tuples, found 1461270 valid tuples.\n",
            "Processed 4070000 tuples, found 1468706 valid tuples.\n",
            "Processed 4080000 tuples, found 1476534 valid tuples.\n",
            "Processed 4090000 tuples, found 1483918 valid tuples.\n",
            "Processed 4100000 tuples, found 1491760 valid tuples.\n",
            "Processed 4110000 tuples, found 1499033 valid tuples.\n",
            "Processed 4120000 tuples, found 1506534 valid tuples.\n",
            "Processed 4130000 tuples, found 1514889 valid tuples.\n",
            "Processed 4140000 tuples, found 1522327 valid tuples.\n",
            "Processed 4150000 tuples, found 1529011 valid tuples.\n",
            "Processed 4160000 tuples, found 1535934 valid tuples.\n",
            "Processed 4170000 tuples, found 1542740 valid tuples.\n",
            "Processed 4180000 tuples, found 1549693 valid tuples.\n",
            "Processed 4190000 tuples, found 1555757 valid tuples.\n",
            "Processed 4200000 tuples, found 1561577 valid tuples.\n",
            "Processed 4210000 tuples, found 1567853 valid tuples.\n",
            "Processed 4220000 tuples, found 1574868 valid tuples.\n",
            "Processed 4230000 tuples, found 1581962 valid tuples.\n",
            "Processed 4240000 tuples, found 1589007 valid tuples.\n",
            "Processed 4250000 tuples, found 1597308 valid tuples.\n",
            "Processed 4260000 tuples, found 1604707 valid tuples.\n",
            "Processed 4270000 tuples, found 1612336 valid tuples.\n",
            "Processed 4280000 tuples, found 1619790 valid tuples.\n",
            "Processed 4290000 tuples, found 1626769 valid tuples.\n",
            "Processed 4300000 tuples, found 1634059 valid tuples.\n",
            "Processed 4310000 tuples, found 1641789 valid tuples.\n",
            "Processed 4320000 tuples, found 1649224 valid tuples.\n",
            "Processed 4330000 tuples, found 1656694 valid tuples.\n",
            "Processed 4340000 tuples, found 1664886 valid tuples.\n",
            "Processed 4350000 tuples, found 1672216 valid tuples.\n",
            "Processed 4360000 tuples, found 1679574 valid tuples.\n",
            "Processed 4370000 tuples, found 1686946 valid tuples.\n",
            "Processed 4380000 tuples, found 1694438 valid tuples.\n",
            "Processed 4390000 tuples, found 1701778 valid tuples.\n",
            "Processed 4400000 tuples, found 1709116 valid tuples.\n",
            "Processed 4410000 tuples, found 1717097 valid tuples.\n",
            "Processed 4420000 tuples, found 1724675 valid tuples.\n",
            "Processed 4430000 tuples, found 1732360 valid tuples.\n",
            "Processed 4440000 tuples, found 1739370 valid tuples.\n",
            "Processed 4450000 tuples, found 1746520 valid tuples.\n",
            "Processed 4460000 tuples, found 1753731 valid tuples.\n",
            "Processed 4470000 tuples, found 1761222 valid tuples.\n",
            "Processed 4480000 tuples, found 1768804 valid tuples.\n",
            "Processed 4490000 tuples, found 1776698 valid tuples.\n",
            "Processed 4500000 tuples, found 1784034 valid tuples.\n",
            "Processed 4510000 tuples, found 1791020 valid tuples.\n",
            "Processed 4520000 tuples, found 1798396 valid tuples.\n",
            "Processed 4530000 tuples, found 1806187 valid tuples.\n",
            "Processed 4540000 tuples, found 1813949 valid tuples.\n",
            "Processed 4550000 tuples, found 1823477 valid tuples.\n",
            "Processed 4560000 tuples, found 1832760 valid tuples.\n",
            "Processed 4570000 tuples, found 1840895 valid tuples.\n",
            "Processed 4580000 tuples, found 1848653 valid tuples.\n",
            "Processed 4590000 tuples, found 1856969 valid tuples.\n",
            "Processed 4600000 tuples, found 1866431 valid tuples.\n",
            "Processed 4610000 tuples, found 1875487 valid tuples.\n",
            "Processed 4620000 tuples, found 1882471 valid tuples.\n",
            "Processed 4630000 tuples, found 1890152 valid tuples.\n",
            "Processed 4640000 tuples, found 1897730 valid tuples.\n",
            "Processed 4650000 tuples, found 1905242 valid tuples.\n",
            "Processed 4660000 tuples, found 1912621 valid tuples.\n",
            "Processed 4670000 tuples, found 1920971 valid tuples.\n",
            "Processed 4680000 tuples, found 1928470 valid tuples.\n",
            "Processed 4690000 tuples, found 1935471 valid tuples.\n",
            "Processed 4700000 tuples, found 1942343 valid tuples.\n",
            "Processed 4710000 tuples, found 1948783 valid tuples.\n",
            "Processed 4720000 tuples, found 1955247 valid tuples.\n",
            "Processed 4730000 tuples, found 1961457 valid tuples.\n",
            "Processed 4740000 tuples, found 1967827 valid tuples.\n",
            "Processed 4750000 tuples, found 1974723 valid tuples.\n",
            "Processed 4760000 tuples, found 1981429 valid tuples.\n",
            "Processed 4770000 tuples, found 1988725 valid tuples.\n",
            "Processed 4780000 tuples, found 1996414 valid tuples.\n",
            "Processed 4790000 tuples, found 2004449 valid tuples.\n",
            "Processed 4800000 tuples, found 2012178 valid tuples.\n",
            "Processed 4810000 tuples, found 2020251 valid tuples.\n",
            "Processed 4820000 tuples, found 2028453 valid tuples.\n",
            "Processed 4830000 tuples, found 2036199 valid tuples.\n",
            "Processed 4840000 tuples, found 2043838 valid tuples.\n",
            "Processed 4850000 tuples, found 2051547 valid tuples.\n",
            "Processed 4860000 tuples, found 2059387 valid tuples.\n",
            "Processed 4870000 tuples, found 2067159 valid tuples.\n",
            "Processed 4880000 tuples, found 2074713 valid tuples.\n",
            "Processed 4890000 tuples, found 2081624 valid tuples.\n",
            "Processed 4900000 tuples, found 2088759 valid tuples.\n",
            "Processed 4910000 tuples, found 2096220 valid tuples.\n",
            "Processed 4920000 tuples, found 2103415 valid tuples.\n",
            "Processed 4930000 tuples, found 2109877 valid tuples.\n",
            "Processed 4940000 tuples, found 2117291 valid tuples.\n",
            "Processed 4950000 tuples, found 2124744 valid tuples.\n",
            "Processed 4960000 tuples, found 2131975 valid tuples.\n",
            "Processed 4970000 tuples, found 2139255 valid tuples.\n",
            "Processed 4980000 tuples, found 2146526 valid tuples.\n",
            "Processed 4990000 tuples, found 2154839 valid tuples.\n",
            "Processed 5000000 tuples, found 2163061 valid tuples.\n",
            "Processed 5010000 tuples, found 2170327 valid tuples.\n",
            "Processed 5020000 tuples, found 2176723 valid tuples.\n",
            "Processed 5030000 tuples, found 2183502 valid tuples.\n",
            "Processed 5040000 tuples, found 2190393 valid tuples.\n",
            "Processed 5050000 tuples, found 2198124 valid tuples.\n",
            "Processed 5060000 tuples, found 2205502 valid tuples.\n",
            "Processed 5070000 tuples, found 2212739 valid tuples.\n",
            "Processed 5080000 tuples, found 2220053 valid tuples.\n",
            "Processed 5090000 tuples, found 2227914 valid tuples.\n",
            "Processed 5100000 tuples, found 2235337 valid tuples.\n",
            "Processed 5110000 tuples, found 2242959 valid tuples.\n",
            "Processed 5120000 tuples, found 2250175 valid tuples.\n",
            "Processed 5130000 tuples, found 2257644 valid tuples.\n",
            "Processed 5140000 tuples, found 2265005 valid tuples.\n",
            "Processed 5150000 tuples, found 2272084 valid tuples.\n",
            "Processed 5160000 tuples, found 2279327 valid tuples.\n",
            "Processed 5170000 tuples, found 2286448 valid tuples.\n",
            "Processed 5180000 tuples, found 2293598 valid tuples.\n",
            "Processed 5190000 tuples, found 2300859 valid tuples.\n",
            "Processed 5200000 tuples, found 2308254 valid tuples.\n",
            "Processed 5210000 tuples, found 2315359 valid tuples.\n",
            "Processed 5220000 tuples, found 2322731 valid tuples.\n",
            "Processed 5230000 tuples, found 2329915 valid tuples.\n",
            "Processed 5240000 tuples, found 2337282 valid tuples.\n",
            "Processed 5250000 tuples, found 2344798 valid tuples.\n",
            "Processed 5260000 tuples, found 2352067 valid tuples.\n",
            "Processed 5270000 tuples, found 2359442 valid tuples.\n",
            "Processed 5280000 tuples, found 2366813 valid tuples.\n",
            "Processed 5290000 tuples, found 2374361 valid tuples.\n",
            "Processed 5300000 tuples, found 2382071 valid tuples.\n",
            "Processed 5310000 tuples, found 2389585 valid tuples.\n",
            "Processed 5320000 tuples, found 2396877 valid tuples.\n",
            "Processed 5330000 tuples, found 2404244 valid tuples.\n",
            "Processed 5340000 tuples, found 2411731 valid tuples.\n",
            "Processed 5350000 tuples, found 2419196 valid tuples.\n",
            "Processed 5360000 tuples, found 2426797 valid tuples.\n",
            "Processed 5370000 tuples, found 2434257 valid tuples.\n",
            "Processed 5380000 tuples, found 2441555 valid tuples.\n",
            "Processed 5390000 tuples, found 2448943 valid tuples.\n",
            "Processed 5400000 tuples, found 2456578 valid tuples.\n",
            "Processed 5410000 tuples, found 2464031 valid tuples.\n",
            "Processed 5420000 tuples, found 2471143 valid tuples.\n",
            "Processed 5430000 tuples, found 2478251 valid tuples.\n",
            "Processed 5440000 tuples, found 2485445 valid tuples.\n",
            "Processed 5450000 tuples, found 2492995 valid tuples.\n",
            "Processed 5460000 tuples, found 2500316 valid tuples.\n",
            "Processed 5470000 tuples, found 2507746 valid tuples.\n",
            "Processed 5480000 tuples, found 2515052 valid tuples.\n",
            "Processed 5490000 tuples, found 2522272 valid tuples.\n",
            "Processed 5500000 tuples, found 2529573 valid tuples.\n",
            "Processed 5510000 tuples, found 2537081 valid tuples.\n",
            "Processed 5520000 tuples, found 2544565 valid tuples.\n",
            "Processed 5530000 tuples, found 2552044 valid tuples.\n",
            "Processed 5540000 tuples, found 2559366 valid tuples.\n",
            "Processed 5550000 tuples, found 2566616 valid tuples.\n",
            "Processed 5560000 tuples, found 2574195 valid tuples.\n",
            "Processed 5570000 tuples, found 2579730 valid tuples.\n",
            "Processed 5580000 tuples, found 2585206 valid tuples.\n",
            "Processed 5590000 tuples, found 2592563 valid tuples.\n",
            "Processed 5600000 tuples, found 2600040 valid tuples.\n",
            "Processed 5610000 tuples, found 2607627 valid tuples.\n",
            "Processed 5620000 tuples, found 2615024 valid tuples.\n",
            "Processed 5630000 tuples, found 2622519 valid tuples.\n",
            "Processed 5640000 tuples, found 2629160 valid tuples.\n",
            "Processed 5650000 tuples, found 2635505 valid tuples.\n",
            "Processed 5660000 tuples, found 2642229 valid tuples.\n",
            "Processed 5670000 tuples, found 2648962 valid tuples.\n",
            "Processed 5680000 tuples, found 2655335 valid tuples.\n",
            "Processed 5690000 tuples, found 2661765 valid tuples.\n",
            "Processed 5700000 tuples, found 2668290 valid tuples.\n",
            "Processed 5710000 tuples, found 2674919 valid tuples.\n",
            "Processed 5720000 tuples, found 2681854 valid tuples.\n",
            "Processed 5730000 tuples, found 2689097 valid tuples.\n",
            "Processed 5740000 tuples, found 2696373 valid tuples.\n",
            "Processed 5750000 tuples, found 2703449 valid tuples.\n",
            "Processed 5760000 tuples, found 2710517 valid tuples.\n",
            "Processed 5770000 tuples, found 2717347 valid tuples.\n",
            "Processed 5780000 tuples, found 2724645 valid tuples.\n",
            "Processed 5790000 tuples, found 2731877 valid tuples.\n",
            "Processed 5800000 tuples, found 2740054 valid tuples.\n",
            "Processed 5810000 tuples, found 2747048 valid tuples.\n",
            "Processed 5820000 tuples, found 2754160 valid tuples.\n",
            "Processed 5830000 tuples, found 2760471 valid tuples.\n",
            "Processed 5840000 tuples, found 2765432 valid tuples.\n",
            "Processed 5850000 tuples, found 2770707 valid tuples.\n",
            "Processed 5860000 tuples, found 2775388 valid tuples.\n",
            "Processed 5870000 tuples, found 2779931 valid tuples.\n",
            "Processed 5880000 tuples, found 2784294 valid tuples.\n",
            "Processed 5890000 tuples, found 2788755 valid tuples.\n",
            "Processed 5900000 tuples, found 2793382 valid tuples.\n",
            "Processed 5910000 tuples, found 2798095 valid tuples.\n",
            "Processed 5920000 tuples, found 2803852 valid tuples.\n",
            "Processed 5930000 tuples, found 2808519 valid tuples.\n",
            "Processed 5940000 tuples, found 2812913 valid tuples.\n",
            "Processed 5950000 tuples, found 2817173 valid tuples.\n",
            "Processed 5960000 tuples, found 2821569 valid tuples.\n",
            "Processed 5970000 tuples, found 2826634 valid tuples.\n",
            "Processed 5980000 tuples, found 2831587 valid tuples.\n",
            "Adding reverse edges ...\n",
            "Creating one whole graph ...\n",
            "Total #nodes: 1885136\n",
            "Total #edges: 5668682\n",
            "Convert to heterograph ...\n",
            "tcmalloc: large alloc 1836654592 bytes == 0x70e20000 @  0x7fab77bc21e7 0x7faabb91d0ce 0x7faabb973cf5 0x7faabb973e08 0x7faabba330f4 0x7faabba3630c 0x7faabbbbd3ac 0x7faabbbbde10 0x59588e 0x595b69 0x7faabb92207d 0x572ade 0x511b33 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n",
            "#Node types: 7\n",
            "#Canonical edge types: 108\n",
            "#Unique edge type names: 96\n",
            "Load training/validation/testing split ...\n",
            "Done saving data into cached files.\n",
            "Epoch 00000/00020 | Train Accuracy: 0.5294 | Train Loss: 1.6893\n",
            "100% 13/13 [00:00<00:00, 91.21it/s]\n",
            "Validation Accuracy: 0.3591\n",
            "Epoch 00001/00020 | Train Accuracy: 0.3235 | Train Loss: 1.8647\n",
            "100% 13/13 [00:00<00:00, 88.02it/s]\n",
            "Validation Accuracy: 0.4713\n",
            "Epoch 00002/00020 | Train Accuracy: 0.4118 | Train Loss: 1.7146\n",
            "100% 13/13 [00:00<00:00, 88.39it/s]\n",
            "Validation Accuracy: 0.5761\n",
            "Epoch 00003/00020 | Train Accuracy: 0.6176 | Train Loss: 1.1815\n",
            "100% 13/13 [00:00<00:00, 87.43it/s]\n",
            "Validation Accuracy: 0.7232\n",
            "Epoch 00004/00020 | Train Accuracy: 0.5294 | Train Loss: 1.3863\n",
            "100% 13/13 [00:00<00:00, 89.03it/s]\n",
            "Validation Accuracy: 0.8155\n",
            "Epoch 00005/00020 | Train Accuracy: 0.7059 | Train Loss: 0.9767\n",
            "100% 13/13 [00:00<00:00, 88.69it/s]\n",
            "Validation Accuracy: 0.8678\n",
            "Epoch 00006/00020 | Train Accuracy: 0.8235 | Train Loss: 0.7449\n",
            "100% 13/13 [00:00<00:00, 86.49it/s]\n",
            "Validation Accuracy: 0.9027\n",
            "Epoch 00007/00020 | Train Accuracy: 0.7941 | Train Loss: 0.6347\n",
            "100% 13/13 [00:00<00:00, 90.34it/s]\n",
            "Validation Accuracy: 0.9214\n",
            "Epoch 00008/00020 | Train Accuracy: 0.8824 | Train Loss: 0.4134\n",
            "100% 13/13 [00:00<00:00, 90.67it/s]\n",
            "Validation Accuracy: 0.9464\n",
            "Epoch 00009/00020 | Train Accuracy: 0.8529 | Train Loss: 0.3542\n",
            "100% 13/13 [00:00<00:00, 91.11it/s]\n",
            "Validation Accuracy: 0.9589\n",
            "Epoch 00010/00020 | Train Accuracy: 0.8824 | Train Loss: 0.3456\n",
            "100% 13/13 [00:00<00:00, 86.54it/s]\n",
            "Validation Accuracy: 0.9651\n",
            "Epoch 00011/00020 | Train Accuracy: 0.8824 | Train Loss: 0.4567\n",
            "100% 13/13 [00:00<00:00, 88.43it/s]\n",
            "Validation Accuracy: 0.9825\n",
            "Epoch 00012/00020 | Train Accuracy: 0.8529 | Train Loss: 0.3984\n",
            "100% 13/13 [00:00<00:00, 88.96it/s]\n",
            "Validation Accuracy: 0.9900\n",
            "Epoch 00013/00020 | Train Accuracy: 0.8824 | Train Loss: 0.3882\n",
            "100% 13/13 [00:00<00:00, 82.37it/s]\n",
            "Validation Accuracy: 0.9938\n",
            "Epoch 00014/00020 | Train Accuracy: 0.9706 | Train Loss: 0.1904\n",
            "100% 13/13 [00:00<00:00, 88.57it/s]\n",
            "Validation Accuracy: 0.9963\n",
            "Epoch 00015/00020 | Train Accuracy: 0.9118 | Train Loss: 0.2779\n",
            "100% 13/13 [00:00<00:00, 89.22it/s]\n",
            "Validation Accuracy: 0.9963\n",
            "Epoch 00016/00020 | Train Accuracy: 0.9412 | Train Loss: 0.1789\n",
            "100% 13/13 [00:00<00:00, 88.79it/s]\n",
            "Validation Accuracy: 0.9963\n",
            "Epoch 00017/00020 | Train Accuracy: 0.9412 | Train Loss: 0.2605\n",
            "100% 13/13 [00:00<00:00, 89.87it/s]\n",
            "Validation Accuracy: 0.9975\n",
            "Epoch 00018/00020 | Train Accuracy: 0.9118 | Train Loss: 0.3408\n",
            "100% 13/13 [00:00<00:00, 86.32it/s]\n",
            "Validation Accuracy: 0.9988\n",
            "Epoch 00019/00020 | Train Accuracy: 0.9706 | Train Loss: 0.0821\n",
            "100% 13/13 [00:00<00:00, 87.65it/s]\n",
            "Validation Accuracy: 0.9988\n",
            "100% 7/7 [00:00<00:00, 23.64it/s]\n",
            "Final Test Accuracy: 0.8636\n"
          ]
        }
      ]
    }
  ]
}